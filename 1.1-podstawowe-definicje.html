<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.1 Podstawowe definicje | Stochastyczne modele układów oddziałujących 2024" />
<meta property="og:type" content="book" />




<meta name="author" content="Piotr Dyszewski" />

<meta name="date" content="2024-10-28" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="1.1 Podstawowe definicje | Stochastyczne modele układów oddziałujących 2024">

<title>1.1 Podstawowe definicje | Stochastyczne modele układów oddziałujących 2024</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>






<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if bootstrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="#podzi%C4%99kowania" id="toc-podziękowania">Podziękowania</a></li>
<li class="has-sub"><a href="#wyk%C5%82ad-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym" id="toc-wykład-łańcuchy-markowa-w-czasie-ciągłym"><span class="toc-section-number">1</span> Wykład: Łańcuchy Markowa w czasie ciągłym</a>
<ul>
<li><a href="1.1-podstawowe-definicje.html#podstawowe-definicje" id="toc-podstawowe-definicje"><span class="toc-section-number">1.1</span> Podstawowe definicje</a></li>
</ul></li>
<li class="has-sub"><a href="#wyk%C5%82ad-drugi-mocna-w%C5%82asno%C5%9B%C4%87-markowa" id="toc-wykład-drugi-mocna-własność-markowa"><span class="toc-section-number">2</span> Wykład drugi: Mocna własność Markowa</a>
<ul>
<li class="has-sub"><a href="2.1-czasy-zatrzymania.html#czasy-zatrzymania" id="toc-czasy-zatrzymania"><span class="toc-section-number">2.1</span> Czasy zatrzymania</a>
<ul>
<li><a href="2.1-czasy-zatrzymania.html#defn:3:1.54" id="toc-defn:3:1.54"><span class="toc-section-number">2.1.1</span> Definicja: czas zatrzymania</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="podstawowe-definicje" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Podstawowe definicje</h2>
<p>Zaczynamy od prezentacji definicji trzech obiektów, na których się skupimy w tym rozdziale. Przypomnijmy, że będziemy definiować łańcuchy Markowa w czasie ciągłym na dyskretnej przestrzeni stanów <span class="math inline">\(S\)</span>. Topologia na <span class="math inline">\(S\)</span> to oczywiście topologia dyskretna, względem której wszystkie funkcje są ciągłe.</p>
<p>Głównym obiektem naszych badań będą procesy stochastyczne. Ze względów technicznych pracować będziemy na bardzo konkretnej przestrzeni zdarzeń elementarnych. Niech <span class="math inline">\(\Omega\)</span> będzie zbiorem prawostronnie ciągłych funkcji <span class="math inline">\(\omega \colon [0, \infty) \to S\)</span> ze skończoną liczbą skoków w dowolnym skończonym przedziale czasowym. Dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span> rozważmy funkcję <span class="math inline">\(X_t \colon \Omega \to S\)</span> zadaną przez
<span class="math display">\[
X_t(\omega) = \omega(t).
\]</span>
Niech <span class="math inline">\(\sigma\)</span>-ciało <span class="math inline">\(\mathcal{F}\)</span> na <span class="math inline">\(\Omega\)</span> będzie najmniejszym takim, że odwzorowanie <span class="math inline">\(\omega \mapsto \omega(t)\)</span> jest mierzalne dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span>. Niech wreszcie dla <span class="math inline">\(s \in \mathbb{R}_+\)</span> oznaczmy przez <span class="math inline">\(\theta_s\)</span> odwzorowanie <span class="math inline">\(\Omega \to \Omega\)</span> zadane przez
<span class="math display">\[
\theta_s(\omega)(t) = \omega(t+s).
\]</span>
W szczególności <span class="math inline">\(X_t \circ \theta_s = X_{t+s}\)</span>. O odwzorowaniu <span class="math inline">\(\theta_s\)</span> można myśleć jak o przesunięciu czasu o <span class="math inline">\(s\)</span>. Zamiast utożsamiać własność Markowa z procesem stochastycznym <span class="math inline">\(X=\{X(t)\}_{t \in \mathbb{R}_+}\)</span>, utożsamimy ją z rodziną miar probabilistycznych na <span class="math inline">\(\Omega\)</span>, względem której <span class="math inline">\(X\)</span> będzie procesem Markowa.</p>
<div class="definition">
<p><span id="def:unlabeled-div-1" class="definition"><strong>Definition 1.1  </strong></span>Łańcuchem Markowa w czasie ciągłym na przestrzeni stanów <span class="math inline">\(S\)</span> nazywamy parę uporządkowaną
<span class="math inline">\(( \mathbf{P}, \mathbb{F})\)</span> taką, że</p>
<ul>
<li><p><strong>(ŁM1)</strong> <span class="math inline">\(\mathbb{F}=(\mathcal{F}_t)_{t \in \mathbb{R}_+}\)</span> jest filtracją względem której
<span class="math inline">\(X = (X(t))_{t \in \mathbb{R}_+}\)</span> jest adaptowalny i
<span class="math inline">\(\mathcal{F}_t \subseteq \mathcal{F}\)</span> dla każdego <span class="math inline">\(t \in \mathbb{R}_+\)</span>.</p></li>
<li><p><strong>(ŁM2)</strong> <span class="math inline">\(\mathbf{P}= \{ \mathbf{P}_x\}_{x \in S}\)</span>. Dla każdego <span class="math inline">\(x \in S\)</span>, <span class="math inline">\(\mathbf{P}_x\)</span> jest miarą probabilistyczną na <span class="math inline">\(\Omega\)</span> taką, że
<span class="math display">\[
\mathbf{P}_x[X_0 = x] = \mathbf{P}_x[\omega \in \Omega : \omega(0)=x]= 1.
\]</span></p></li>
<li><p><strong>(ŁM3)</strong> Spełniona jest własność Markowa
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s] = \mathbf{E}_{X(s)}[Y] \text{ p.n. } \mathbf{P}_x
\]</span>
dla wszystkich <span class="math inline">\(x \in S\)</span> i wszystkich ograniczonych mierzalnych <span class="math inline">\(Y\)</span> na <span class="math inline">\(\Omega\)</span>.</p></li>
</ul>
</div>
<p>W powyższej definicji <span class="math inline">\(\mathbf{E}_x\)</span> jest wartością oczekiwaną odpowiadającą
mierze probabilistycznej <span class="math inline">\(\mathbf{P}_x\)</span>, czyli
<span class="math display">\[
\mathbf{E}_x[Y] = \int_\Omega Y(\omega) \: \mathbf{P}_x(\mathrm{d} \omega).
\]</span>
O zmiennej losowej <span class="math inline">\(Y \colon \Omega \to \mathbb{R}\)</span>
można myśleć jak o statystyce całej trajektorii procesu
<span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span>. Załóżmy, że <span class="math inline">\(Y\)</span> jest postaci
<span class="math display">\[
Y(\omega) = f(\omega(t_1), \omega(t_2), \ldots , \omega(t_n)) = f(X(t_1), X(t_2), \ldots, X(t_n))
\]</span>
dla pewnej mierzalnej i ograniczonej funkcji <span class="math inline">\(f \colon \mathbb{R}^n \to \mathbb{R}\)</span>
(dla ćwiczenia warto sprawdzić, że <span class="math inline">\(Y\)</span> powyższej postaci jest istotnie zmienną losową, tj. jest mierzalna względem <span class="math inline">\(\mathcal{F}\)</span>).
Wówczas
<span class="math display">\[
Y\circ \theta_s(\omega) = f(\omega(t_1+s), \omega(t_2+s), \ldots , \omega(t_n+s)) = f(X(t_1+s), X(t_2+s), \ldots, X(t_n+s)).
\]</span>
Własność Markowa w Definicji mówi zatem to, co powinna. Rozkład wektora losowego <span class="math inline">\((X(t_1+s), X(t_2+s), \ldots, X(t_n+s))\)</span> pod warunkiem <span class="math inline">\(\mathcal{F}_s\)</span> jest taki sam, jak rozkład wektora <span class="math inline">\((X&#39;(t_1), X&#39;(t_2), \ldots, X&#39;(t_n))\)</span> dla <span class="math inline">\(X&#39;=\{X&#39;(t)\}_{t\in \mathbb{R}_+}\)</span> będącym niezależną kopią <span class="math inline">\(X\)</span>, zapoczątkowaną w <span class="math inline">\(X_0&#39;=X(s)\)</span>.</p>
<p>Naszym nadrzędnym celem będzie sprowadzenie powyższej definicji do bardziej przystępnych terminów. Zanim jednak do tego przejdziemy, rozważmy następujący przykład.</p>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Example 1.1  </strong></span>Niech <span class="math inline">\(N=(N_t)_{t \in \mathbb{R}_+}\)</span> będzie jednorodnym
procesem Poissona z intensywnością <span class="math inline">\(\lambda &gt;0\)</span> określonym na przestrzeni
probabilistycznej <span class="math inline">\((\Sigma, \mathcal{G}, \mathbb{P})\)</span>.
Przypomnijmy, że oznacza to, że <span class="math inline">\(t \mapsto N_t\)</span> jest prawostronnie ciągła oraz
dla każdego <span class="math inline">\(t&gt;0\)</span> zmienna losowa <span class="math inline">\(N_t\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda&gt;0\)</span>,
<span class="math display">\[
\mathbb{P}[N_t=k] = e^{-\lambda} \frac{\lambda^k}{k!},
\]</span>
i wreszcie dla <span class="math inline">\(t&gt;s\geq 0\)</span>, zmienna <span class="math inline">\(N_t - N_s\)</span> jest niezależna
od <span class="math inline">\(\sigma\)</span>-ciała <span class="math inline">\(\mathcal{F}_s^N = \sigma(N_r : r \leq s)\)</span>.
Uzasadnimy, że <span class="math inline">\(N\)</span> jest procesem Markowa w sensie przyjętej przez nas definicji.
Przestrzenią stanów jest <span class="math inline">\(S = \mathbb{N}\)</span>.
Niech <span class="math inline">\(\mathbf{P}_x[A] = \mathbb{P}[N + x \in A]\)</span> dla <span class="math inline">\(A \in \mathcal{F}\)</span>.
Tutaj <span class="math inline">\(x+N\)</span> oznacza funkcję <span class="math inline">\(t \mapsto N_t + x\)</span>.
Pokażemy teraz, że spełniona jest własność Markowa.</p>
<p>Dla <span class="math inline">\(A \in \mathcal{F}_s\)</span> mamy
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[Y(N \circ \theta_s + x) \mathbf{1}_{N \in A}]
= \mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{N \in A}].
\]</span>
Skoro <span class="math inline">\(A \in \mathcal{F}_s\)</span>, to <span class="math inline">\(\{N \in A\} \in \mathcal{F}_s^N\)</span> (zadanie).
Skoro <span class="math inline">\(N \circ \theta_s - N_s = (N_{t+s} - N_s)_{t \in \mathbb{R}_+}\)</span>
jest niezależny od <span class="math inline">\(\mathcal{F}_s^N\)</span>, to
<span class="math display">\[
\mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{N \in A} | \mathcal{F}_s] = \mathbf{1}_{N \in A} \cdot y(N_s + x),
\]</span>
gdzie
<span class="math display">\[
y(k) = \mathbb{E}[Y(N \circ \theta_s - N_s + k)] = \mathbf{E}^k[Y].
\]</span>
Podsumowując,
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[y(N_s + x) \mathbf{1}_{N \in A}]
= \mathbf{E}_x[y(X(s)) \mathbf{1}_A]
\]</span>
odwołując się teraz do definicji warunkowej wartości oczekiwanej
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s]
= y(X(s))
= \mathbf{E}_{X(s)}[Y].
\]</span></p>
</div>
<p>Powyższy przykład pokazuje, że uzasadnienie własności Markowa wprost z definicji nie jest najprostszym zadaniem.
Przekonamy się w przyszłości, że taka forma jest przydatna do teoretycznych rozważań.
Mimo to przyda się nam bardziej przystępny sposób mówienia o łańcuchach Markowa w czasie ciągłym.
Odnosząc się do czasu dyskretnego, korzystać będziemy z funkcji przejścia.</p>
<div class="definition">
<p><span id="def:defn-2-trans" class="definition"><strong>Definition 1.2  </strong></span>Funkcją przejścia nazywamy rodzinę odwzorowań <span class="math inline">\(p = (p_t)_{t \in \mathbb{R}_+}\)</span>,
gdzie <span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zdefiniowanych dla <span class="math inline">\(t \ge 0\)</span> takich, że
<span class="math display">\[
p_t(x, y) \ge 0, \quad \sum_{y \in S} p_t(x, y) = 1, \quad \lim_{t \to 0} p_t(x, x) = p_0(x, x) = 1,
\]</span>
spełniających równania Chapmana-Kolmogorowa
<span class="math display">\[
p_{s+t}(x, y) = \sum_{z \in S} p_s(x, z)p_t(z, y).
\]</span></p>
</div>
<p>Interpretacją wartości <span class="math inline">\(p_t(x,y)\)</span> jest prawdopodobieństwo,
że w czasie <span class="math inline">\(t\)</span> proces przejdzie ze stanu <span class="math inline">\(x\)</span> do stanu <span class="math inline">\(y\)</span>.
Innymi słowy,
<span class="math display">\[
p_t(x,y) = \mathbf{P}_x[X_t = y].
\]</span>
Jak się niebawem przekonamy,
dzięki własności Markowa pozwala ona jednoznacznie wyznaczyć rozkład procesu,
tj. jednoznacznie wyznaczyć miarę <span class="math inline">\(\mathbf{P}_x\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Example 1.2  </strong></span>Rozważmy <span class="math inline">\(S = \mathbb{N}\)</span>, <span class="math inline">\(\lambda &gt; 0\)</span> oraz
<span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zadane przez
<span class="math display">\[
p_t(x, y) = e^{-\lambda t} \frac{(\lambda t)^{y - x}}{(y - x)!} \mathbf{1}_{\{y \geq x\}}.
\]</span>
Wówczas <span class="math inline">\(p\)</span> jest funkcją przejścia.
Wystarczy zauważyć, że <span class="math inline">\(p_t(x)\)</span> to prawdopodobieństwo, że zmienna losowa o
rozkładzie Poissona z parametrem <span class="math inline">\(\lambda t\)</span> jest równa <span class="math inline">\(y - x\)</span>.
Równania Chapmana-Kołmogorowa wynikają z następującej własności rozkładu Poissona:
jeżeli niezależne zmienne losowe <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> mają rozkłady Poissona odpowiednio z
parametrami <span class="math inline">\(\lambda t\)</span> i <span class="math inline">\(\lambda s\)</span>,
to <span class="math inline">\(X + Y\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda (t + s)\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-4" class="theorem"><strong>Theorem 1.1  </strong></span>Dla łańcucha Markowa <span class="math inline">\((\mathbf{P}, \mathbb{F})\)</span> połóżmy
<span class="math display">\[
p_t(x, y) = \mathbf{P}_x[X_t = y]
\]</span>
dla <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x, y \in S\)</span>. Wówczas:</p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(p_t(x, y)\)</span> jest funkcją przejścia,</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(p_t(x, y)\)</span> określa miary <span class="math inline">\(\mathbf{P}_x\)</span> jednoznacznie.</li>
</ol></li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-5" class="proof"><em>Proof</em>. </span><strong>(a)</strong> Najpierw pokażemy, że <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.
Przez prawostronną ciągłość ścieżek,
<span class="math inline">\(\tau = \inf \{ t &gt; 0 : X_t \neq X_0 \} &gt; 0\)</span> <span class="math inline">\(\mathbf{P}_x\)</span>-p.w.
dla dowolnego <span class="math inline">\(x\)</span> z <span class="math inline">\(S\)</span>.
Ponieważ <span class="math inline">\(p_t(x, x) \ge \mathbf{P}_x[\tau &gt; t] \to 1\)</span>
przy <span class="math inline">\(t \to 0\)</span>, to istotnie <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.</p>
<p>Równania Chapmana-Kołmogorowa wynikają z własności Markowa.
Aby to zobaczyć, rozważmy <span class="math inline">\(Y = 1_{\{ X(t)=y \}}\)</span>.
Własność Markowa zapisuje się jako
<span class="math display">\[
    \mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s]
    = \mathbf{P}_{X(s)}[X_t = y]
    = p_t(X(s), y) \text{ p.n. } \mathbf{P}_x.
\]</span>
Biorąc wartości oczekiwane względem <span class="math inline">\(\mathbf{P}_x\)</span> w tej tożsamości,
otrzymujemy równania Chapmana-Kołmogorowa.
<span class="math display">\[
    \mathbf{P}_x[X_{t+s}=y]
    = \mathbf{E}_x \left[\mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s] \right]
    = \mathbf{E}_x\left[ p_t(X(s), y) \right]
    = \sum_{z \in S } p_t(z, y) p_s(x, z).
\]</span>
To dowodzi (a).
<strong>(b)</strong> Użyjemy własności Markowa wielokrotnie, aby otrzymać
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = p_{t_1}(x, x_1) p_{t_2 - t_1}(x_1, x_2) \cdots p_{t_n - t_{n-1}}(x_{n-1}, x_n)
\]</span>
dla <span class="math inline">\(0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> oraz <span class="math inline">\(x_1, \ldots, x_n \in S\)</span>.
Aby to zobaczyć oznaczmy
<span class="math display">\[
    \mathcal{H}_{n-1} = \{ X(t_1) = x_1, \ldots, X(t_{n-1}) = x_{n-1} \} \in \mathcal{F}_{t_{n-1}}.
\]</span>
Z własności Markowa
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{P}_x[\mathcal{H}_{n-1}, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X \circ \theta_{t_{n-1}} (t_n - t_{n-1}) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_{X(t_{n-1})}[X (t_n - t_{n-1}) = x_n]
    = \mathbf{1}_{\mathcal{H}_{n-1}} p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Biorąc wartości oczekiwane,
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = \mathbf{P}_x[\mathcal{H}_{n-1}] p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Postulowaną równość otrzymujemy przez iterację powyższej procedury.
Udowodniona właśnie równość uzasadnia,
że funkcja przejścia określa rozkłady skończenie wymiarowe <span class="math inline">\(\mathbf{P}_x\)</span>.
Określa również pełną miarę <span class="math inline">\(\mathbf{P}_x\)</span>,
ponieważ miary prawdopodobieństwa na <span class="math inline">\((\Omega, \mathcal{F})\)</span> są określane
przez ich skończenie wymiarowe rozkłady w świetle twierdzenia <span class="math inline">\(\pi - \lambda\)</span>.
Aby to zobaczyć, załóżmy, że <span class="math inline">\(\mu\)</span> oraz <span class="math inline">\(\nu\)</span> to dwie takie miary,
które mają te same skończenie wymiarowe rozkłady,
i niech <span class="math inline">\(\mathcal{P}\)</span> będą skończenie wymiarowymi zbiorami w <span class="math inline">\((\Omega, \mathcal{F})\)</span> oraz
<span class="math display">\[
    \mathcal{L} = \{ A \in \mathcal{F} : \mu(A) = \nu(A) \}.
\]</span>
Wówczas <span class="math inline">\(\mathcal{L}\)</span> jest <span class="math inline">\(\lambda\)</span>-układem zawierającym
<span class="math inline">\(\pi\)</span>-układ <span class="math inline">\(\mathcal{P}\)</span>.
Przez twierdzenie <span class="math inline">\(\pi - \lambda\)</span>,
<span class="math inline">\(\sigma(\mathcal{P}) \subseteq \mathcal{L}\)</span>.
Skoro <span class="math inline">\(\sigma(\mathcal{P}) = \mathcal{F}\)</span>,
to <span class="math inline">\(\mu(A) = \nu(A)\)</span> dla wszystkich <span class="math inline">\(A \in \mathcal{F}\)</span>.</p>
</div>
<p>Skoro <span class="math inline">\(X\)</span> jest elementem <span class="math inline">\(\Omega\)</span>,
zbioru funkcji prawostronnie ciągłych o wartościach w przeliczalnym <span class="math inline">\(S\)</span>,
to <span class="math inline">\(X\)</span> jest funkcją kawałkami stałą.
W rezultacie do opisu <span class="math inline">\(X\)</span> wystarczy sprecyzować,
w jaki sposób <span class="math inline">\(X\)</span> zmienia wartość.
Opis ten jest dokonywany w kategoriach <span class="math inline">\(Q\)</span>-macierzy.</p>
<div class="definition">
<p><span id="def:defn-2-qm" class="definition"><strong>Definition 1.3  </strong></span><span class="math inline">\(Q\)</span>-macierzą nazywamy macierz <span class="math inline">\((q(x, y))_{x,y \in S}\)</span>
liczb rzeczywistych indeksowanych przez <span class="math inline">\(x, y \in S\)</span>,
które spełniają
<span class="math display">\[
q(x, y) \ge 0 \text{ dla } x \neq y \quad \text{oraz} \quad \sum_y q(x, y) = 0.
\]</span></p>
</div>
<p>Ponieważ wyrazy diagonalne są niedodatnie i
odgrywają specjalną rolę,
naturalne jest użycie specjalnego oznaczenia dla nich:
<span class="math display">\[
c(x) = -q(x, x).
\]</span>
Przejście od funkcji przejścia do <span class="math inline">\(Q\)</span>-macierzy
jest trudniejsze niż przejście od procesu do funkcji przejścia
i wymaga dokonania dodatkowych założeń.
Zaczynamy od kilku własności, które obowiązują dla wszystkich funkcji przejścia.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-6" class="theorem"><strong>Theorem 1.2  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>Wówczas <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla wszystkich <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x \in S\)</span>.</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>Jeśli <span class="math inline">\(p_t(x, x) = 1\)</span> dla pewnego <span class="math inline">\(t &gt; 0\)</span> oraz <span class="math inline">\(x \in S\)</span>, wtedy <span class="math inline">\(p_t(x, x) = 1\)</span> dla wszystkich <span class="math inline">\(t &gt; 0\)</span> oraz tego <span class="math inline">\(x\)</span>.</li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-alpha">
<li>Dla każdego <span class="math inline">\(x, y \in S\)</span>, <span class="math inline">\(p_t(x, y)\)</span> jest jednostajnie ciągła w <span class="math inline">\(t\)</span>. Dokładniej,
<span class="math display">\[
|p_t(x, y) - p_s(x, y)| \leq 1 - p_{|t-s|}(x, x).
\]</span></li>
</ol></li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span><strong>(a)</strong> Najpierw zauważmy, że <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla małych <span class="math inline">\(t\)</span> zgodnie z
przyjętą Definicją <span class="math inline">\(\ref{defn-2-trans}\)</span>.
Z równań Chapmana-Kołmogorowa,
<span class="math display">\[
p_{s+t}(x, x) \geq p_s(x, x)p_t(x, x),
\]</span>
więc ścisła dodatniość rozciąga się na wszystkie <span class="math inline">\(t\)</span>.</p>
<p><strong>(b)</strong> Użyjmy równania Chapmana-Kołmogorowa raz jeszcze, aby napisać
<span class="math display">\[
p_{s+t}(x, x) \leq p_s(x, x)p_t(x, x) + [1 - p_s(x, x)] = 1 - p_s(x, x)[1 - p_t(x, x)].
\]</span>
Zatem, jeśli <span class="math inline">\(p_{s+t}(x, x) = 1\)</span>, to <span class="math inline">\(p_t(x, x) = 1\)</span>,
ponieważ <span class="math inline">\(p_s(x, x) &gt; 0\)</span> z części (a).
Stąd <span class="math inline">\(\{ t \ge 0 : p_t(x, x) = 1 \}\)</span> jest przedziałem zaczynającym się od 0.
Z dowodu części (a) wynika, że musi to być cała dodatnia oś.</p>
<p><strong>(c)</strong> Aby uzasadnić (c), ponownie użyjmy równania Chapmana-Kołmogorowa,
aby napisać
<span class="math display">\[
p_{t+s}(x, y) - p_t(x, y) = p_t(x, y)[p_s(x, x) - 1] + \sum_{z \neq x} p_s(x, z)p_t(z, y).
\]</span>
Pierwszy składnik po prawej stronie jest niedodatni,
a drugi jest nieujemny. Wartość bezwzględna każdego z nich nie jest większa niż <span class="math inline">\(1 - p_s(x, x)\)</span>.
To pociąga postulowaną nierówność, która z kolei pociąga jednostajną ciągłość.</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-8" class="theorem"><strong>Theorem 1.3  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>Dla każdego <span class="math inline">\(x\)</span>, prawostronna pochodna
<span class="math display">\[
  c(x) = -q(x, x) = - \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, x) \right|_{t=0} \in [0, \infty]
  \]</span>
istnieje i spełnia
<span class="math display">\[
  p_t(x, x) \ge e^{-c(x)t}.
  \]</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>Jeśli <span class="math inline">\(c(x) &lt; \infty\)</span>, wtedy dla tego <span class="math inline">\(x\)</span> i dla wszystkich <span class="math inline">\(y \neq x\)</span>, prawostronna pochodna
<span class="math display">\[
  q(x, y) = \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) \right|_{t=0} \in [0, \infty)
  \]</span>
istnieje oraz
<span class="math display">\[
  \sum_{y \in S} q(x, y) \leq 0.
  \]</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-alpha">
<li>Jeśli dla pewnego <span class="math inline">\(x \in S\)</span>,
<span class="math inline">\(c(x) &lt; \infty\)</span> i <span class="math inline">\(\sum_y q(x, y) = 0\)</span>, to <span class="math inline">\(p_t(x, y)\)</span>
jest różniczkowalna w sposób ciągły względem <span class="math inline">\(t\)</span> dla tego <span class="math inline">\(x\)</span> i każdego <span class="math inline">\(y\)</span>,
oraz spełnia równania retrospektywne Kołmogorowa:
<span class="math display">\[
  \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) = \sum_z q(x, z)p_t(z, y).
  \]</span></li>
</ol></li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-9" class="proof"><em>Proof</em>. </span>Niech <span class="math inline">\(f(t) = - \log p_t(x, x)\)</span>.
Wówczas <span class="math inline">\(f\)</span> jest dobrze określona i jednostajnie ciągła.
Jest ona też subaddytywna.
Zatem, zgodnie z Lematem Fekete,
<span class="math display">\[
    c(x) = \lim_{t \to 0} \frac{f(t)}{t} \in [0, \infty]
\]</span>
i spełnia <span class="math inline">\(f(t) \leq c(x)t\)</span>. To daje część (a).</p>
<p><strong>(b)</strong> Przypuśćmy, że <span class="math inline">\(c(x) &lt; \infty\)</span>. Z dowiedzionej właśnie nierówności,
<span class="math display">\[
    1 - p_t(x, x) \leq 1 - e^{-c(x)t} \leq c(x)t,
\]</span>
i stąd
<span class="math display">\[
    \sum_{y : y \neq x} \frac{p_t(x, y)}{t} \leq c(x).
\]</span>
Zatem,
<span class="math display">\[\begin{equation}\label{eq-2-1}
    \limsup_{t \to 0} \frac{p_t(x, y)}{t} &lt; \infty
\end{equation}\]</span>
dla <span class="math inline">\(y \neq x\)</span>.
Niech <span class="math inline">\(q(x, y)\)</span> będzie wartością powyższej granicy górnej.
Aby pokazać, że granica rzeczywiście istnieje,
weźmy <span class="math inline">\(\delta &gt; 0\)</span> i dodatnią liczbę całkowitą <span class="math inline">\(n\)</span>.
Macierz <span class="math inline">\(p_{\delta}(x, y)\)</span> można traktować jako prawdopodobieństwa
przejścia dla dyskretnego łańcucha Markowa na <span class="math inline">\(S\)</span>,
a wtedy zgodnie z równaniami Chapmana-Kołmogorowa,
odpowiadające <span class="math inline">\(n\)</span>-krokowe prawdopodobieństwa przejścia są dane przez <span class="math inline">\(p_{n\delta}(x, y)\)</span>.
Rozkładając zdarzenie,
że ten łańcuch znajduje się w <span class="math inline">\(y\)</span> w czasie <span class="math inline">\(n\)</span>
zgodnie z czasem pierwszej wizyty w <span class="math inline">\(y\)</span>, mamy dla <span class="math inline">\(y \neq x\)</span>,
<span class="math display">\[
    p_{n\delta}(x, y) \geq \sum_{k=0}^{n-1} p_{k\delta}^k(x, x) p_{\delta}(x, y)p_{(n-k-1)\delta}(y, y).
\]</span>
Stąd
<span class="math display">\[
    \frac{p_{n\delta}(x, y)}{n\delta}
    \geq \frac{p_{\delta}(x, y)}{\delta} e^{-c(x)n\delta} \inf_{0 \leq s \leq n\delta} p_s(y, y).
\]</span>
Teraz niech <span class="math inline">\(\delta \downarrow 0\)</span> wzdłuż
ciągu realizującego granicę górną w~<span class="math inline">\(\eqref{eq-2-1}\)</span>, tak że
<span class="math display">\[
\frac{p_{\delta}(x, y)}{\delta} \to q(x, y).
\]</span>
Wybierzmy teraz <span class="math inline">\(n \to \infty\)</span> tak, że <span class="math inline">\(n\delta \to t\)</span>. Wówczas
<span class="math display">\[
\frac{p_t(x, y)}{t} \geq q(x, y)e^{-c(x)t} \inf_{0 \leq s \leq t} p_s(y, y)
\]</span>
dla <span class="math inline">\(t &gt; 0\)</span>. Zatem,
<span class="math display">\[
\liminf_{t \to 0} \frac{p_t(x, y)}{t} \geq q(x, y).
\]</span>
Postulowana nierówność wynika teraz z lematu Fatou.</p>
<p><strong>(c)</strong> Napiszmy
<span class="math display">\[
\frac{p_{t+s}(x, y) - p_t(x, y)}{s} = \sum_z \left[ \frac{p_s(x, z) - p_0(x, z)}{s} - q(x, z) \right] p_t(z, y).
\]</span>
Każdy wyraz w sumie dąży do <span class="math inline">\(0\)</span>, gdy <span class="math inline">\(s \downarrow 0\)</span>,
zgodnie z pierwszymi dwoma częściami twierdzenia.
Zatem musimy kontrolować ogony sumy.
Weźmy skończony zbiór <span class="math inline">\(T \subset S\)</span> zawierający <span class="math inline">\(x\)</span> i zauważmy, że
<span class="math display">\[
\sum_{z \notin T} \left| \frac{p_s(x, z)}{s} - q(x, z) \right| p_t(z, y) \leq \sum_{z \notin T} \frac{p_s(x, z)}{s} + \sum_{z \notin T} q(x, z)
\]</span>
<span class="math display">\[
= s^{-1} \left[ 1 - \sum_{z \in T} p_s(x, z) \right] - \sum_{z \in T} q(x, z) \to -2 \sum_{z \in T} q(x, z)
\]</span>
gdy <span class="math inline">\(s \downarrow 0\)</span>.
Granicę po prawej stronie można uczynić dowolnie małą,
wybierając <span class="math inline">\(T\)</span> duże, ponieważ <span class="math inline">\(\sum_z q(x, z) = 0\)</span>.
Zatem prawa strona dąży do zera,
gdy <span class="math inline">\(s \downarrow 0\)</span>. To dowodzi, że prawostronne pochodne <span class="math inline">\(p_t(x, y)\)</span>
istnieją i spełniają zadaną równość.
Aby zobaczyć, że obustronne pochodne rzeczywiście istnieją,
wystarczy zauważyć, że prawa strona jest ciągła w <span class="math inline">\(t\)</span> i użyć faktu,
że funkcja ciągła z ciągłą prawostronną pochodną jest różniczkowalna.</p>
</div>

</div>
<!-- </div> -->
<p style="text-align: center;">
<a href="1-wykład-łańcuchy-markowa-w-czasie-ciągłym.html"><button class="btn btn-default">Previous</button></a>
<a href="2-wykład-drugi-mocna-własność-markowa.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
