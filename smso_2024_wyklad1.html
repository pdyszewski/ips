<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>smso_2024_wyklad1</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<div class="center">
<hr />
<p><strong><span class="smallcaps">Stoch. modele systemów
oddziuałujących 2024</span></strong></p>
<p><span class="smallcaps">wykład 1: łańcuchy Markowa w czasie
ciągłym</span></p>
<hr />
</div>
<p>Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie
ciągłym na przeliczalnym (lub skończonym) zbiorze <span
class="math inline">\(S\)</span> w oparciu o jest opis infinitezymalny.
W następnym rozdziale zbadamy problem konstrukcji dla procesów na
bardziej ogólnej przestrzeni stanów. Na razie ograniczamy naszą uwagę do
bardziej konkretnej sytuacji przeliczalnego <span
class="math inline">\(S\)</span>. W tym przypadku często używa się słowa
„łańcuch” zamiast „proces”.</p>
<p>Przypomnijmy, że łańcuchem Markowa w czasie dyskretnym nazywamy
proces stochastyczny <span class="math inline">\(\{X_n\}_{n \in
\mathbb{N}}\)</span> takie, że dla dowolnego <span
class="math inline">\(n \in \mathbb{N}\)</span> i dowolnych <span
class="math inline">\(s_0, s_1, \ldots, s_n \in S\)</span> takich, że
<span class="math display">\[\mathbb{P}\left[ X_{n-1}=s_{n-1}, \:
X_{n-2}=s_{n-2}, \ldots , X_0=s_0 \right]&gt;0\]</span> zachodzi <span
class="math display">\[\begin{gathered}
        \mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1},
            \: X_{n-2}=s_{n-2}, \ldots , X_0=s_0 \right]=\\
        \mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1} \right].
    
\end{gathered}\]</span> Powyższa własność jest bardzo często przytaczana
jako wyjściowa definicja łańcucha Markowa. Mimo swojej prostoty, która
ułatwia czytelnikom pierwsze zetknięcie z własnością Markowa, własność
ta ma jedną wadę, która ujawnia się przy bardziej zaawansowanych
rozważaniach teoretycznych. Jeżeli chcemy badać tylko procesy na
<strong>przeliczalnej</strong> przestrzeni stanów, to jedno naturalne
uogólnienie ma następującą formę. Proces stochastyczny w czasie ciągłym
<span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span>
nazwiemy łańcuchem Markowa w czasie ciągłym na przeliczlanej przestrzeni
stanów <span class="math inline">\(S\)</span>, jeżeli dla dowolnego
<span class="math inline">\(n\)</span> i dowolnych <span
class="math inline">\(0\leq t_0&lt; t_1&lt; \ldots &lt; t_n\)</span> i
dowolnych <span class="math inline">\(s_0, s_1, \ldots, s_n \in
S\)</span> takich, że <span class="math display">\[\label{eq:2:markow?}
        \mathbb{P}\left[ X(t_{n-1})=s_{n-1}, \: X(t_{n-2})=s_{n-2},
\ldots , X(t_0)=s_0 \right]&gt;0\]</span> zachodzi <span
class="math display">\[\begin{gathered}
        \mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1},
            \: X(t_{n-2})=s_{n-2}, \ldots , X(t_0)=s_0 \right]=\\
        \mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1} \right].
    
\end{gathered}\]</span> Powyższa własność nie jest zbyt przydatna,
jeżeli chcemy badać procesy na nieprzeliczalnej przestrzeni stanów. Dla
bardzo wielu naturalnych obiektów zmienne losowe <span
class="math inline">\(X(t)\)</span> w badanym przez nas procesie mogą
mieć rozkład ciągły. Oznacza to, że warunek <a href="#eq:2:markow?"
data-reference-type="eqref"
data-reference="eq:2:markow?">[eq:2:markow?]</a> nie jest spełniony dla
dowolnego wyboru parametrów.</p>
<p>W celu znalezienia bardziej elastycznego warunku zauważmy, że
własność Markowa dla jednorodnego łańcucha Markowa <span
class="math inline">\(\{X_n\}_{n \in \mathbb{N}}\)</span> w czasie
dyskretnym z macierzą przejścia <span class="math display">\[p(i,j) =
\mathbb{P}[X_1=j \: | \: X_0=i]\]</span> zapisuje się jako <span
class="math display">\[\mathbb{P}[X_n = j \: | \: \mathcal{F}_n] =
p(X_n,j),\]</span> gdzie <span class="math inline">\(\mathcal{F}_n =
\sigma(X_0, X_1, \ldots, X_n)\)</span>. Dokładne uzasadnienie powyższej
własności pozostawiamy jako zadanie. Podobnie, dla dowolnego <span
class="math inline">\(m \in \mathbb{N}\)</span>, <span
class="math display">\[\mathbb{P}[X_{n+m} = j \: | \: \mathcal{F}_n] =
p^{(m)}(X_n,j),\]</span> gdzie <span class="math inline">\((p^{(m)(i,j)
}_{i, j \in S}\)</span> jest <span class="math inline">\(m\)</span>-tą
potęgą macierzy przejścia <span class="math display">\[p^{(m)}(i,j) =
\mathbb{P}[X_m=j \: | \: X_0=i]\]</span> Oznacza to, że dla dowolnej
funkcji mierzalnej <span class="math inline">\(f \colon S \to
\mathbb{R}\)</span>, <span class="math display">\[\mathbb{E}[ f(X_{n+m})
\: | \: \mathcal{F}_n] = \sum_{s \in S} f(s) p^{(m)}(X_n, s).\]</span>
Powyższa definicja względnie łatwo zapisuje się w czasie ciągłym <span
class="math display">\[\label{eq:2:markow??}
        \mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] = \sum_{x\in S}
f(x) p^{(t)}(X_n, x),\]</span> gdzie <span
class="math display">\[p^{(t)}(y,x) = \mathbb{P}[X_t=x |
X_0=y].\]</span> Relacja <a href="#eq:2:markow??"
data-reference-type="eqref"
data-reference="eq:2:markow??">[eq:2:markow??]</a> daje się zapisać w
przypadku nieprzeliczalnej przestrzeni stanów jako <span
class="math display">\[\mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] =
\int_S f(x) p^{(t)}(X_n, \mathrm{d}x),\]</span> gdzie <span
class="math display">\[p^{(t)}(y, \mathrm{d}x) = \mathbb{P}[X_t \in
\mathrm{d}x | X_0=y]\]</span> jest rozkładem <span
class="math inline">\(X_t\)</span> pod warunkiem <span
class="math inline">\(\{X_0=y\}\)</span>. To niesie ze sobą koleje
problemy, ponieważ tak jak wcześniej zauważyliśmy <span
class="math inline">\(\{X_0=y\}\)</span> może być zdarzeniem o
prawdopodobieństwie zero. Przedstawione podejście jest do uratowania pod
kątem formalnym przez odniesienie się do regularnych rozkładów
warunkowych. Zamiast tego podejdziemy do problemy od innej strony.
Naszym punktem wyjścia będzie odpowiednia rodzina miar. Jak zobaczymy
wkrótce to podejście będzie również opierało się o odpowiednik <a
href="#eq:2:markow??" data-reference-type="eqref"
data-reference="eq:2:markow??">[eq:2:markow??]</a>. Oznacza to, że w
rezultacie będziemy opisywali tę samą klasę procesów stochastycznych bez
konieczności obchodzenia się z warunkowaniem po zdarzeniach
niemożliwych.</p>
<h1 id="podstawowe-definicje">Podstawowe definicje</h1>
<p>Zaczynamy od prezentacji definicji trzech obiektów, na których się
skupimy w tym rozdziale. Przypomnijmy, że będziemy definiować łańcuchy
Markowa w czasie ciągłym na dyskretnej przestrzeni stanów <span
class="math inline">\(S\)</span>. Topologia na <span
class="math inline">\(S\)</span> to oczywiście topologia dyskretna,
względem której wszystkie funkcje są ciągłe.</p>
<p>Głównym obiektem naszych badań będą procesy stochastyczne. Ze
względów technicznych pracować będziemy na bardzo konkretnej przestrzeni
zdarzeń elementarnych. Niech <span class="math inline">\(\Omega\)</span>
będzie zbiorem prawostronnie ciągłych funkcji <span
class="math inline">\(\omega \colon [0, \infty) \to S\)</span> ze
skończoną liczbą skoków w dowolnym skończonym przedziale czasowym. Dla
każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0,
+\infty)\)</span> rozważmy funkcję <span class="math inline">\(X_t
\colon \Omega \to S\)</span> zadaną przez <span
class="math display">\[X_t(\omega) = \omega(t).\]</span> Niech <span
class="math inline">\(\sigma\)</span>-ciało <span
class="math inline">\(\mathcal{F}\)</span> na <span
class="math inline">\(\Omega\)</span> będzie najmniejszym takim, że
odwzorowanie <span class="math inline">\(\omega \mapsto
\omega(t)\)</span> jest mierzalne dla każdego <span
class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span>. Niech
wreszcie dla <span class="math inline">\(s \in \mathbb{R}_+\)</span>
oznaczmy przez <span class="math inline">\(\theta_s\)</span>
odwzorowanie <span class="math inline">\(\Omega \to \Omega\)</span>
zadane przez <span class="math display">\[\theta_s(\omega)(t) =
\omega(t+s).\]</span> W szczególności <span class="math inline">\(X_t
\circ \theta_s = X_{t+s}\)</span>. O odwzorowaniu <span
class="math inline">\(\theta_s\)</span> można myśleć jak o przesunięciu
czasu o <span class="math inline">\(s\)</span>. Zamiast utożsamiać
własność Markowa z procesem stochastycznym <span
class="math inline">\(X=\{X(t)\}_{t \in \mathbb{R}_+}\)</span>
utożsamimy ją w rodziną miar probabilistycznych na <span
class="math inline">\(\Omega\)</span> względem której <span
class="math inline">\(X\)</span> będzie procesem Markowa.</p>
<div id="defn:2:Ligg2.1" class="defn">
<p><strong>Definicja 1</strong>. Łańcuchem Markowa w czasie ciągłym na
przestrzeni stanów <span class="math inline">\(S\)</span> nazywamy parę
uporządkowaną <span class="math inline">\(( \mathbf{P},
\mathbb{F})\)</span> taką, że</p>
<ul>
<li><p><span class="math inline">\(\mathbb{F}=(\mathcal{F}_t)_{t \in
\mathbb{R}_+}\)</span> jest filtracją względem której <span
class="math inline">\(X = (X(t))_{t \in \mathbb{R}_+}\)</span> jest
adaptowalny i <span class="math inline">\(\mathcal{F}_t \subseteq
\mathcal{F}\)</span> dla każdego <span class="math inline">\(t \in
\mathbb{R}_+\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{P}= \{ \mathbf{P}_x\}_{x \in
S}\)</span>. Dla każdego <span class="math inline">\(x \in S\)</span>,
<span class="math inline">\(\mathbf{P}_x\)</span> jest miarą
probabilistyczną na <span class="math inline">\(\Omega\)</span> taką, że
<span class="math display">\[\mathbf{P}_x[X_0 = x] =
                    \mathbf{P}_x[\omega \in \Omega \: : \: \omega(0)=x]=
1.\]</span></p></li>
<li><p>Spełniona jest własność Markowa <span
class="math display">\[\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s] =
                    \mathbf{E}_{X(s)}[Y] \text{ p.n. }
\mathbf{P}_x\]</span> dla wszystkich <span class="math inline">\(x \in
S\)</span> i wszystkich ograniczonych mierzalnych <span
class="math inline">\(Y\)</span> na <span
class="math inline">\(\Omega\)</span>.</p></li>
</ul>
</div>
<p>W powyższej definicji <span
class="math inline">\(\mathbf{E}_x\)</span> jest wartością oczekiwaną
odpowiadającą mierze probabilistycznej <span
class="math inline">\(\mathbf{P}_x\)</span>, czyli <span
class="math display">\[\mathbf{E}_x[Y] = \int_\Omega Y(\omega) \:
\mathbf{P}_x(\mathrm{d}\omega).\]</span> O zmiennej losowej <span
class="math inline">\(Y \colon \Omega \to \mathbb{R}\)</span> można
myśleć jak o statystyce całej trajektorii procesu <span
class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span>. Załóżmy,
że <span class="math inline">\(Y\)</span> jest postaci <span
class="math display">\[Y(\omega) = f(\omega(t_1), \omega(t_2), \ldots ,
\omega(t_n))
        = f(X(t_1), X(t_2), \ldots, X(t_n))\]</span> dla pewnej
mierzalnej o ograniczonej funkcji <span class="math inline">\(f \colon
\mathbb{R}^n \to \mathbb{R}\)</span> (dla ćwiczenia warto sprawdzić, że
<span class="math inline">\(Y\)</span> powyższej postaci jest istotnie
zmienną losową, tj. jest mierzalne względem <span
class="math inline">\(\mathcal{F}\)</span>). Wówczas <span
class="math display">\[\begin{gathered}
        Y\circ \theta_s(\omega) = f(\omega(t_1+s), \omega(t_2+s), \ldots
, \omega(t_n+s)) = \\
        f(X(t_1+s), X(t_2+s), \ldots, X(t_n+s)).
    
\end{gathered}\]</span> Własność Markowa w Definicji <a
href="#defn:2:Ligg2.1" data-reference-type="ref"
data-reference="defn:2:Ligg2.1">1</a> mówi zatem to, co powinna. Rozkład
wektora losowego <span class="math inline">\((X(t_1+s), X(t_2+s),
\ldots, X(t_n+s))\)</span> pod warunkiem <span
class="math inline">\(\mathcal{F}_s\)</span> jest taki sam, jak rozkład
waktora <span class="math inline">\((X&#39;(t_1), X&#39;(t_2), \ldots,
X&#39;(t_n))\)</span> dla <span
class="math inline">\(X&#39;=\{X&#39;(t)\}_{t\in \mathbb{R}_+}\)</span>
będącym niezależną kopią <span class="math inline">\(X\)</span>
zapoczątkowaną w <span class="math inline">\(X_0&#39;=X(s)\)</span>.</p>
<p>Naszym nadrzędnym celem będzie sprowadzenie powyższej Definicji <a
href="#defn:2:Ligg2.1" data-reference-type="ref"
data-reference="defn:2:Ligg2.1">1</a> do bardziej przystępnych terminów.
Zanim jednak do tego przejdziemy rozważmy następujący przykład.</p>
<div class="ex">
<p><strong>Przyklad 2</strong>. Niech <span
class="math inline">\(N=(N_t)_{t \in \mathbb{R}_+}\)</span> będzie
jednorodnym procesem Poissona z intensywnością <span
class="math inline">\(\lambda &gt;0\)</span> określonym na przestrzeni
probabilistycznej <span class="math inline">\((\Sigma, \mathcal{G},
\mathbb{P})\)</span>. Przypomnijmy, że oznacza to, że <span
class="math inline">\(t \mapsto N_t\)</span> jest prawostronnie ciągła
oraz dla każdego <span class="math inline">\(t&gt;0\)</span> zmienna
losowa <span class="math inline">\(N_t\)</span> ma rozkład Poissona z
parametrem <span class="math inline">\(\lambda&gt;0\)</span>, <span
class="math display">\[\mathbb{P}[N_t=k] = e^{-\lambda}
\frac{\lambda^k}{k!}\]</span> i wreszcie dla <span
class="math inline">\(t&gt;s\geq 0\)</span>, zmienna <span
class="math inline">\(N_t-N_s\)</span> jest niezależna od <span
class="math inline">\(\sigma\)</span>-ciała <span
class="math inline">\(\mathcal{F}_s^N = \sigma(N_r \: : \: r \leq
s)\)</span>. Uzasadnimy, że <span class="math inline">\(N\)</span> jest
procesem Markowa w sensie przyjętej przez nas definicji. Przestrzenią
stanów jest <span class="math inline">\(S = \mathbb{N}\)</span>. Niech
<span class="math inline">\(\mathbf{P}_x[A] = \mathbb{P}[N+x \in
A]\)</span> dla <span class="math inline">\(A \in \mathcal{F}\)</span>.
Tutaj <span class="math inline">\(x+N\)</span> oznacza funkcję <span
class="math inline">\(t \mapsto N_t+x\)</span>. Pokażemy teraz, że
spełniona jest własność Markowa. Dla <span class="math inline">\(A \in
\mathcal{F}_s\)</span> mamy <span class="math display">\[\mathbf{E}_x[Y
\circ \theta_s \mathbf{1}_{A}] = \mathbb{E}[Y(N \circ \theta_s+x)
\mathbf{1}_{N \in A}]=
            \mathbb{E}[Y(N \circ \theta_s - N_s +N_s+x) \mathbf{1}_{N
\in A}].\]</span> Skoro <span class="math inline">\(A \in
\mathcal{F}_s\)</span>, to <span class="math inline">\(\{N \in A \} \in
\mathcal{F}_s^N\)</span> (zadanie). Skoro <span
class="math inline">\(N\circ \theta_s-N_s = (N_{t+s}-N_s)_{t \in
\mathbb{R}_+}\)</span> jest niezależny od <span
class="math inline">\(\mathcal{F}_s^N\)</span>, to <span
class="math display">\[\mathbb{E}[Y(N \circ \theta_s - N_s +N_s+x)
\mathbf{1}_{N \in A} | \mathcal{F}_s]= \mathbf{1}_{N\in A}
y(N_s+x),\]</span> gdzie <span class="math display">\[y(k) =
\mathbb{E}[Y(N \circ \theta_s - N_s +k)]= \mathbf{E}^k[Y].\]</span>
Podsumowując <span class="math display">\[\mathbf{E}_x[Y \circ \theta_s
\mathbf{1}_{A}] = \mathbb{E}[y(N_s+x) \mathbf{1}_{N \in A}]=
\mathbf{E}_x[y(X(s)) \mathbf{1}_A]\]</span> odwołując się teraz do
definicji warunkowej wartości oczekiwanej <span
class="math display">\[\mathbf{E}_x[Y \circ \theta_s |\mathcal{F}_s] =
y(X(s)) = \mathbf{E}_{X(s)}[Y].\]</span></p>
</div>
<p>Powyższy przykład pokazuje, że uzasadnienie własności Markowa wprost
z definicji nie jest najprostszym zadaniem. Przekonamy się w
przyszłości, że taka forma jest przydatna do teoretycznych rozważań.
Mimo to przyda się nam bardziej przystępny sposób mówienia o łańcuchach
Markowa w czasie ciągłym. Odnosząc się co czasu dyskretnego, korzystać
będziemy z funkcji przejścia.</p>
<div id="defn:2:trans" class="defn">
<p><strong>Definicja 3</strong>. Funkcją przejścia nazywamy rodzinę
odwzorowań <span class="math inline">\(p = (p_t)_{t \in
\mathbb{R}_+}\)</span>, <span class="math inline">\(p_t \colon S \times
S \to [0,1]\)</span> zdefiniowanych dla <span class="math inline">\(t
\ge 0\)</span> takich, że <span class="math display">\[p_t(x, y) \ge 0,
\quad \sum_{y\in S} p_t(x, y) = 1, \quad \lim_{t \to 0} p_t(x, x) =
p_0(x, x) = 1,\]</span> spełniających równania Chapmana-Kolmogorowa
<span class="math display">\[p_{s+t}(x, y) = \sum_{z \in S} p_s(x,
z)p_t(z, y).\]</span></p>
</div>
<p>Interpretacją wartości <span class="math inline">\(p_t(x,y)\)</span>
jest prawdopodobieństwo, że w czasie <span
class="math inline">\(t\)</span> proces przejdzie ze stanu <span
class="math inline">\(x\)</span> do stanu <span
class="math inline">\(y\)</span>. Innymi słowy <span
class="math display">\[p_t(x,y) = \mathbf{P}_x[X_t=y].\]</span> Jak się
niebawem przekonamy w połączeniu z własnością Markowa pozwala ona
jednoznacznie wyznaczyć rozkład procesu, tj. jednoznacznie wyznaczyć
miarę <span class="math inline">\(\mathbf{P}_x\)</span>.</p>
<div class="ex">
<p><strong>Przyklad 4</strong>. Rozważmy <span class="math inline">\(S =
\mathbb{N}\)</span>, <span class="math inline">\(\lambda&gt;0\)</span>
oraz <span class="math inline">\(p_t \colon S \times S \to
[0,1]\)</span> zadane przez <span class="math display">\[p_t(x,y) =
e^{-\lambda t} \frac{(\lambda t)^{y-x}}{(y-x)!} \mathbf{1}_{\{y \geq
x\}}.\]</span> Wówczas <span class="math inline">\(p\)</span> jest
funkcją przejścia. Wystarczy zauważyć, że <span
class="math inline">\(p_t(x)\)</span> to prawdopodobieństwo, że zmienna
losowa o rozkładzie Poissona z parametrem <span
class="math inline">\(\lambda t\)</span> jest równa <span
class="math inline">\(y-x\)</span>. Równania Chapmana-Kołmogorowa
wynikają z następującej własności rozkładu Poissona: jeżeli niezależne
zmienne losowe <span class="math inline">\(X\)</span> i <span
class="math inline">\(Y\)</span> mają rozkłady Poissona odpowiednio z
parametrami <span class="math inline">\(\lambda t\)</span> i <span
class="math inline">\(\lambda s\)</span>, to <span
class="math inline">\(X+Y\)</span> ma rozkład Poissona z parametrem
<span class="math inline">\(\lambda (t+s)\)</span>.</p>
</div>
<div class="thm">
<p><strong>Twierdzenie 5</strong>. Dla łańcucha Markowa <span
class="math inline">\((\mathbf{P}, \mathbb{F})\)</span> połóżmy <span
class="math display">\[p_t(x, y) = \mathbf{P}_x[X_t = y]\]</span> dla
<span class="math inline">\(t \ge 0\)</span> oraz <span
class="math inline">\(x, y \in S\)</span>. Wówczas:</p>
<ul>
<li><p><span class="math inline">\(p_t(x, y)\)</span> jest funkcją
przejścia,</p></li>
<li><p><span class="math inline">\(p_t(x, y)\)</span> określa miary
<span class="math inline">\(\mathbf{P}_x\)</span>
jednoznacznie.</p></li>
</ul>
</div>
<div class="proof">
<p><em>Proof.</em> (a) Najpierw pokażemy, że <span
class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>. Przez
prawostronną ciągłość ścieżek, <span class="math inline">\(\tau = \inf
\{ t &gt; 0 : X_t \neq X_0 \} &gt; 0\)</span> <span
class="math inline">\(\mathbf{P}^x\)</span>-p.w. dla dowolnego <span
class="math inline">\(x\)</span> z <span
class="math inline">\(S\)</span>. Ponieważ <span
class="math inline">\(p_t(x, x) \ge \mathbf{P}_x[\tau &gt; t] \to
1\)</span> przy <span class="math inline">\(t\to 0\)</span>, to istotnie
<span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.</p>
<p>Równania Chapmana-Kolmogorowa wynikają z własności Markowa. Aby to
zobaczyć rozważmy <span class="math inline">\(Y = 1_{\{ X(t)=y
\}}\)</span>. Własność Markowa zapisuje się jako <span
class="math display">\[\mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s] =
\mathbf{P}_{X(s)}[X_t = y] = p_t(X(s), y) \text{ p.n. }
\mathbf{P}^x.\]</span> Biorąc wartości oczekiwane względem <span
class="math inline">\(\mathbf{P}^x\)</span> w tej tożsamości,
otrzymujemy równania Chapmana-Kołmogorowa. <span
class="math display">\[\mathbf{P}_x[X_{t+s}=y]=\mathbf{E}_x
\left[\mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s] \right] \\
            =  \mathbf{E}_x\left[ p_t(X(s), y) \right] = \sum_{z \in S }
p_t(z,y) p_s(x,z).\]</span> To dowodzi (a). Dla (b), użyjemy własności
Markowa wielokrotnie, aby otrzymać <span
class="math display">\[\mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
= p_{t_1}(x, x_1)p_{t_2-t_1}(x_1, x_2)
            \cdots p_{t_n-t_{n-1}}(x_{n-1}, x_n)\]</span> dla <span
class="math inline">\(0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> oraz
<span class="math inline">\(x_1, \ldots, x_n \in S\)</span>. Aby to
zobaczyć oznaczmy <span class="math display">\[\mathcal{H}_{n-1} = \{
X(t_1) = x_1, \ldots, X(t_{n-1}) = x_{n-1}\} \in
\mathcal{F}_{t_{n-1}}.\]</span> Z własności Markowa <span
class="math display">\[\begin{gathered}
        \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n|
\mathcal{F}_{t_{n-1}}] =
        \mathbf{P}_x[\mathcal{H}_{n-1}, X(t_n) = x_n|
\mathcal{F}_{t_{n-1}}] =\\
        \mathbf{1}_{\mathcal{H}_{n-1}}\mathbf{P}_x[X(t_n) = x_n|
\mathcal{F}_{t_{n-1}}] =
        \mathbf{1}_{\mathcal{H}_{n-1}}\mathbf{P}_x[X\circ
\theta_{t_{n-1}} (t_n-t_{n-1}) = x_n| \mathcal{F}_{t_{n-1}}] =\\
    \mathbf{1}_{\mathcal{H}_{n-1}}\mathbf{P}_{X(t_{n-1})}[X
(t_n-t_{n-1})=x_n] =
    \mathbf{1}_{\mathcal{H}_{n-1}}\mathbf{P}_{x_{n-1}}[X
(t_n-t_{n-1})=x_n] =\\
    \mathbf{1}_{\mathcal{H}_{n-1}}p_{t_n-t_{n-1}}(x_{n-1}, x_n).
    
\end{gathered}\]</span> Biorąc wartości oczekiwane <span
class="math display">\[\mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
= \mathbf{P}_x[\mathcal{H}_{n-1}]
        p_{t_n-t_{n-1}}(x_{n-1}, x_n)\]</span> Postulowaną równość
otrzymujemy przez iterację powyższej procedury. Udowodniona właśnie
równość uzasadnia, że funkcja przejścia określa rozkłady skończenie
wymiarowe <span class="math inline">\(\mathbf{P}_x\)</span>. Określa
również pełną miarę <span class="math inline">\(\mathbf{P}_x\)</span>,
ponieważ miary prawdopodobieństwa na <span
class="math inline">\((\Omega, \mathcal{F})\)</span> są określane przez
ich skończenie wymiarowe rozkłady w świetle twierdzenia <span
class="math inline">\(\pi - \lambda\)</span>. Aby to zobaczyć, załóżmy,
że <span class="math inline">\(\mu\)</span> oraz <span
class="math inline">\(\nu\)</span> to dwie takie miary, które mają te
same skończenie wymiarowe rozkłady, i niech <span
class="math inline">\(\mathcal{P}\)</span> będą skończenie wymiarowymi
zbiorami w <span class="math inline">\((\Omega, \mathcal{F})\)</span>
oraz <span class="math display">\[\mathcal{L} = \{ A \in \mathcal{F} :
\mu(A) = \nu(A) \}.\]</span> Wówczas <span
class="math inline">\(\mathcal{L}\)</span> jest <span
class="math inline">\(\lambda\)</span>-układem zawierającym <span
class="math inline">\(\pi\)</span>-układ <span
class="math inline">\(\mathcal{P}\)</span>. Przez twierdzenie <span
class="math inline">\(\pi - \lambda\)</span>, <span
class="math inline">\(\sigma(\mathcal{P}) \subseteq
\mathcal{L}\)</span>. Skoro <span
class="math inline">\(\sigma(\mathcal{P}) = \mathcal{F}\)</span>, to
<span class="math inline">\(\mu(A) = \nu(A)\)</span> dla wszystkich
<span class="math inline">\(A \in \mathcal{F}\)</span>. ◻</p>
</div>
<p>Skoro <span class="math inline">\(X\)</span> jest elementem <span
class="math inline">\(\Omega\)</span>, zbioru funkcji prawostronne
ciągłych o wartościach w przeliczalnym <span
class="math inline">\(S\)</span>, to <span
class="math inline">\(X\)</span> jest kawałkami stałą funkcją. W
rezultacie do opisu <span class="math inline">\(X\)</span> wystarczy
sprecyzować w jaki sposób <span class="math inline">\(X\)</span> zmienia
wartość. Opis ten jest dokonywany w kategoriach <span
class="math inline">\(Q\)</span>-macierzy.</p>
<div id="defn:2:qm" class="defn">
<p><strong>Definicja 6</strong>. <span
class="math inline">\(Q\)</span>-macierzą nazywamy <span
class="math inline">\((q(x, y))_{x,y\in S}\)</span> liczb rzeczywistych
indeksowanych przez <span class="math inline">\(x, y \in S\)</span>,
który spełnia <span class="math display">\[q(x, y) \ge 0 \text{ dla } x
\ne y \quad \text{oraz} \quad \sum_y q(x, y) = 0.\]</span></p>
</div>
<p>Ponieważ wyrazy diagonalne są niedodatnie i odgrywają specjalną rolę,
naturalne jest użycie specjalnego oznaczenia dla nich: <span
class="math display">\[c(x) = -q(x, x).\]</span></p>
<p>Przejście od funkcji przejścia do <span
class="math inline">\(Q\)</span>-macierzy jest trudniejsze i wymaga
dokonania dodatkowych założeń. Zaczynamy od kilku własności, które
obowiązują dla wszystkich funkcji przejścia.</p>
<div class="thm">
<p><strong>Twierdzenie 7</strong>. Załóżmy, że <span
class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ul>
<li><p>Wówczas <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla
wszystkich <span class="math inline">\(t \ge 0\)</span> oraz <span
class="math inline">\(x \in S\)</span>.</p></li>
<li><p>Jeśli <span class="math inline">\(p_t(x, x) = 1\)</span> dla
pewnego <span class="math inline">\(t &gt; 0\)</span> oraz <span
class="math inline">\(x \in S\)</span>, wtedy <span
class="math inline">\(p_t(x, x) = 1\)</span> dla wszystkich <span
class="math inline">\(t &gt; 0\)</span> oraz tego <span
class="math inline">\(x\)</span>.</p></li>
<li><p>Dla każdego <span class="math inline">\(x, y \in S\)</span>,
<span class="math inline">\(p_t(x, y)\)</span> jest jednostajnie ciągła
w <span class="math inline">\(t\)</span>. Dokładniej <span
class="math display">\[|p_t(x, y) - p_s(x, y)| \leq 1 - p_{|t-s|}(x,
x).\]</span></p></li>
</ul>
</div>
<div class="proof">
<p><em>Proof.</em> Dla części (a), najpierw zauważmy, że <span
class="math inline">\(p_t(x, x) &gt; 0\)</span> dla małych <span
class="math inline">\(t\)</span> zgodnie z przyjętą Definicją <a
href="#defn:2:trans" data-reference-type="ref"
data-reference="defn:2:trans">3</a>. Z równań Chapmana-Kołmogorowa,
<span class="math display">\[p_{s+t}(x, x) \geq p_s(x, x)p_t(x,
x),\]</span> więc ścisła dodatniość rozciąga się na wszystkie <span
class="math inline">\(t\)</span>. Dla części (b), użyjmy równania
Chapmana-Kołmogorowa raz jeszcze, aby napisać <span
class="math display">\[p_{s+t}(x, x) \leq p_s(x, x)p_t(x, x) + [1 -
p_s(x, x)]=1-p_s(x,x)[1-p_t(x,x)].\]</span> Zatem, jeśli <span
class="math inline">\(p_{s+t}(x, x) = 1\)</span>, to <span
class="math inline">\(p_t(x, x) = 1\)</span>, ponieważ <span
class="math inline">\(p_s(x, x) &gt; 0\)</span> z części (a). Stąd <span
class="math inline">\(\{ t \ge 0 : p_t(x, x) = 1 \}\)</span> jest
przedziałem zaczynającym się od 0. Z dowodu części (a) wynika, musi to
być cała dodatnia oś. Wreszcie aby uzasadnić (c), ponownie użyjmy
równania Chapmana-Kołmogorowa, aby napisać <span
class="math display">\[p_{t+s}(x, y) - p_t(x, y) = p_t(x, y)[p_s(x, x) -
1]
            + \sum_{z \neq x} p_s(x, z)p_t(z, y).\]</span> Pierwszy
składnik po prawej stronie jest niedodatni, a drugi jest nieujemny.
Wartość bezwzględna każdego z nich nie jest większa <span
class="math inline">\(1 - p_s(x, x)\)</span>. To pociąga postulowaną
nierówność, która z kolei pociąga jednostajną ciągłość. ◻</p>
</div>
<div class="thm">
<p><strong>Twierdzenie 8</strong>. Załóżmy, że <span
class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ul>
<li><p>Dla każdego <span class="math inline">\(x\)</span>, prawostronna
pochodna <span class="math display">\[c(x) = -q(x, x)
                    = - \left. \frac{\mathrm{d}}{\mathrm{d}t} p_t(x, x)
\right|_{t=0}
                        \in [0, \infty]\]</span> istnieje i spełnia
<span class="math display">\[p_t(x, x) \ge e^{-c(x)t}.\]</span></p></li>
<li><p>Jeśli <span class="math inline">\(c(x) &lt; \infty\)</span>,
wtedy dla tego <span class="math inline">\(x\)</span> i dla wszystkich
<span class="math inline">\(y \neq x\)</span>, prawostronna pochodna
<span class="math display">\[q(x, y) = \left.
\frac{\mathrm{d}}{\mathrm{d}t} p_t(x, y) \right|_{t=0}
                        \in [0, \infty).\]</span> istnieje oraz <span
class="math display">\[\sum_{y \in S} q(x,y) \leq 0.\]</span></p></li>
<li><p>Jeśli dla pewnego <span class="math inline">\(x \in S\)</span>,
<span class="math inline">\(c(x) &lt; \infty\)</span> i <span
class="math inline">\(\sum_y q(x, y) = 0\)</span>, to <span
class="math inline">\(p_t(x, y)\)</span> jest różniczkowalna w sposób
ciągły względem <span class="math inline">\(t\)</span> dla tego <span
class="math inline">\(x\)</span> i każdego <span
class="math inline">\(y\)</span>, oraz spełnia równania retrospektywne
Kołmogorowa: <span class="math display">\[\frac{\mathrm{d}}{\mathrm{d}t}
p_t(x, y) = \sum_z q(x, z)p_t(z, y).\]</span></p></li>
</ul>
</div>
<div class="proof">
<p><em>Proof.</em> Niech <span class="math inline">\(f(t) = - \log
p_t(x, x)\)</span>. Wówczas <span class="math inline">\(f\)</span> jest
dobrze określona i jednostajnie ciągła. Jest ona też subaddytywna.
Zatem, zgodnie z Lematem Fekete <span class="math display">\[c(x) =
\lim_{t \to 0} \frac{f(t)}{t} \in [0, \infty]\]</span> i spełnia <span
class="math inline">\(f(t) \leq c(x)t\)</span>. To daje część (a). Dla
części (b), przypuśćmy, że <span class="math inline">\(c(x) &lt;
\infty\)</span>. Z dowiedzionej właśnie nierówności <span
class="math display">\[1 - p_t(x, x) \leq 1 - e^{-c(x)t} \leq
c(x)t,\]</span> i stąd <span class="math display">\[\sum_{y:y \neq x}
\frac{p_t(x, y)}{t} \leq c(x).\]</span> Zatem, <span
class="math display">\[\label{eq:2:1}
            \limsup_{t \to 0} \frac{p_t(x, y)}{t} &lt; \infty\]</span>
dla <span class="math inline">\(y \neq x\)</span>. Niech <span
class="math inline">\(q(x, y)\)</span> będzie wartością powyższej
granicy górnej. Aby pokazać, że granica rzeczywiście istnieje, weźmy
<span class="math inline">\(\delta &gt; 0\)</span> i dodatnią liczbę
całkowitą <span class="math inline">\(n\)</span>. Macierz <span
class="math inline">\(p_{\delta}(x, y)\)</span> można traktować jako
prawdopodobieństwa przejścia dla dyskretnego łańcucha Markowa na <span
class="math inline">\(S\)</span>, a wtedy zgodnie z równaniami
Chapmana-Kołmogorowa, odpowiadające <span
class="math inline">\(n\)</span>-krokowe prawdopodobieństwa przejścia są
dane przez <span class="math inline">\(p_{n\delta}(x, y)\)</span>.
Rozkładając zdarzenie, że ten łańcuch znajduje się w <span
class="math inline">\(y\)</span> w czasie <span
class="math inline">\(n\)</span> zgodnie z czasem pierwszej wizyty w
<span class="math inline">\(y\)</span>, daje dla <span
class="math inline">\(y \neq x\)</span>, <span
class="math display">\[p_{n\delta}(x, y) \geq \sum_{k=0}^{n-1}
p_{k\delta}^k(x, x)
            p_{\delta}(x, y)p_{(n-k-1)\delta}(y, y).\]</span> Stąd <span
class="math display">\[\frac{p_{n\delta}(x, y)}{n\delta} \geq
            \frac{p_{\delta}(x, y)}{\delta} e^{-c(x)n\delta}
                \inf_{0 \leq s \leq n\delta} p_s(y, y).\]</span> Teraz
niech <span class="math inline">\(\delta \downarrow 0\)</span> wzdłuż
ciągu realizującego granicę górną w <a href="#eq:2:1"
data-reference-type="eqref" data-reference="eq:2:1">[eq:2:1]</a>, tak że
<span class="math display">\[\frac{p_{\delta}(x, y)}{\delta} \to q(x,
y).\]</span> Wybierzmy teraz <span class="math inline">\(n \to
\infty\)</span> tak, że <span class="math inline">\(n\delta \to
t\)</span>. Wówczas <span class="math display">\[\frac{p_t(x, y)}{t}
\geq q(x, y)e^{-c(x)t} \inf_{0 \leq s \leq t} p_s(y, y)\]</span> dla
<span class="math inline">\(t &gt; 0\)</span>. Zatem, <span
class="math display">\[\liminf_{t \to 0} \frac{p_t(x, y)}{t} \geq q(x,
y).\]</span> Postulowana nierówność wynika teraz z lematu Fatou.
Przechodząc do części (c) napiszmy <span
class="math display">\[\frac{p_{t+s}(x, y) - p_t(x, y)}{s} = \sum_z
\left[ \frac{p_s(x, z) - p_0(x, z)}{s} - q(x, z) \right] p_t(z,
y).\]</span> Każdy wyraz w sumie dąży do <span
class="math inline">\(0\)</span>, gdy <span class="math inline">\(s
\downarrow 0\)</span> zgodnie z pierwszymi dwoma częściami twierdzenia.
Zatem musimy kontrolować ogony sumy. Weźmy skończony zbiór <span
class="math inline">\(T \subset S\)</span> zawierający <span
class="math inline">\(x\)</span> i zauważmy, że <span
class="math display">\[\sum_{z \notin T} \left| \frac{p_s(x, z)}{s} -
q(x, z) \right| p_t(z, y)
        \leq \sum_{z \notin T} \frac{p_s(x, z)}{s} + \sum_{z \notin T}
q(x, z)\]</span> <span class="math display">\[= s^{-1} \left[ 1 -
\sum_{z \in T} p_s(x, z) \right] - \sum_{z \in T} q(x, z) \to -2 \sum_{z
\in T} q(x, z)\]</span> gdy <span class="math inline">\(s \downarrow
0\)</span>. Granicę po prawej stronie można uczynić dowolnie małą,
wybierając <span class="math inline">\(T\)</span> duże, ponieważ <span
class="math inline">\(\sum_z q(x, z) = 0\)</span>. Zatem prawa strona
dąży do zera, gdy <span class="math inline">\(s \downarrow 0\)</span>.
To dowodzi, że prawostronne pochodne <span class="math inline">\(p_t(x,
y)\)</span> istnieją i spełniają zadaną równość. Aby zobaczyć, że
obustronne pochodne rzeczywiście istnieją, wystarczy zauważyć, że prawa
strona jest ciągła w <span class="math inline">\(t\)</span> i użyć
faktu, że funkcja ciągła z ciągłą prawostronną pochodną jest
różniczkowalna. ◻</p>
</div>
</body>
</html>
