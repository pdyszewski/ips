<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Wykład 1: Łańcuchy Markowa w czasie ciągłym | SMUO_wyklad1.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Wykład 1: Łańcuchy Markowa w czasie ciągłym | SMUO_wyklad1.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Wykład 1: Łańcuchy Markowa w czasie ciągłym | SMUO_wyklad1.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="test.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path=""><a href="#wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym"><i class="fa fa-check"></i>Wykład 1: Łańcuchy Markowa w czasie ciągłym</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#podstawowe-definicje"><i class="fa fa-check"></i>Podstawowe definicje</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="wykład-1-łańcuchy-markowa-w-czasie-ciągłym" class="section level1 unnumbered hasAnchor">
<h1>Wykład 1: Łańcuchy Markowa w czasie ciągłym<a href="#wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>2024-10-03</p>
<p><em>Piotr Dyszewski</em></p>
<p>Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie ciągłym na przeliczalnym (lub skończonym)
zbiorze <span class="math inline">\(S\)</span> w oparciu o jego opis infinitezymalny. W następnym rozdziale zbadamy problem konstrukcji dla procesów
na bardziej ogólnej przestrzeni stanów.
Na razie ograniczamy naszą uwagę do bardziej konkretnej sytuacji przeliczalnego <span class="math inline">\(S\)</span>.
W tym przypadku często używa się słowa “łańcuch” zamiast “proces”.</p>
<p>Przypomnijmy, że łańcuchem Markowa w czasie dyskretnym nazywamy proces stochastyczny
<span class="math inline">\(\{X_n\}_{n \in \mathbb{N}}\)</span> takie, że dla dowolnego <span class="math inline">\(n \in \mathbb{N}\)</span> i
dowolnych <span class="math inline">\(s_0, s_1, \ldots, s_n \in S\)</span> takich, że
<span class="math display">\[
\mathbb{P}\left[ X_{n-1}=s_{n-1}, \: X_{n-2}=s_{n-2}, \ldots , X_0=s_0 \right]&gt;0
\]</span>
zachodzi
<span class="math display">\[
\mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1}, \: X_{n-2}=s_{n-2}, \ldots , X_0=s_0 \right]=
\mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1} \right].
\]</span>
Powyższa własność jest bardzo często przytaczana jako wyjściowa definicja łańcucha Markowa. Mimo swojej prostoty, która ułatwia czytelnikom pierwsze zetknięcie z własnością Markowa, własność ta ma jedną wadę, która ujawnia się przy bardziej zaawansowanych rozważaniach teoretycznych.</p>
<p>Jeżeli chcemy badać tylko procesy na <strong>przeliczalnej</strong> przestrzeni stanów, to jedno naturalne uogólnienie ma następującą formę. Proces stochastyczny w czasie ciągłym <span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span> nazwiemy łańcuchem Markowa w czasie ciągłym na przeliczalnej przestrzeni stanów <span class="math inline">\(S\)</span>, jeżeli dla dowolnego <span class="math inline">\(n\)</span> i dowolnych <span class="math inline">\(0 \leq t_0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> i dowolnych <span class="math inline">\(s_0, s_1, \ldots, s_n \in S\)</span> takich, że
<span class="math display">\[
\mathbb{P}\left[ X(t_{n-1})=s_{n-1}, \: X(t_{n-2})=s_{n-2}, \ldots , X(t_0)=s_0 \right]&gt;0
\]</span>
zachodzi
<span class="math display">\[
\mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1}, \: X(t_{n-2})=s_{n-2}, \ldots , X(t_0)=s_0 \right]=
\mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1} \right].
\]</span>
Powyższa własność nie jest zbyt przydatna, jeżeli chcemy badać procesy na nieprzeliczalnej przestrzeni stanów. Dla bardzo wielu naturalnych obiektów zmienne losowe <span class="math inline">\(X(t)\)</span> w badanym przez nas procesie mogą mieć rozkład ciągły. Oznacza to, że warunek powyższy nie jest spełniony dla dowolnego wyboru parametrów.</p>
<p>W celu znalezienia bardziej elastycznego warunku zauważmy,
że własność Markowa dla jednorodnego łańcucha Markowa
<span class="math inline">\(\{X_n\}_{n \in \mathbb{N}}\)</span> w czasie dyskretnym z macierzą przejścia
<span class="math display">\[
p(i,j) = \mathbb{P}[X_1=j \: | \: X_0=i]
\]</span>
zapisuje się jako
<span class="math display">\[
\mathbb{P}[X_n = j \: | \: \mathcal{F}_n] = p(X_n,j),
\]</span>
gdzie <span class="math inline">\(\mathcal{F}_n = \sigma(X_0, X_1, \ldots, X_n)\)</span>.
Dokładne uzasadnienie powyższej własności pozostawiamy jako zadanie.
Podobnie, dla dowolnego <span class="math inline">\(m \in \mathbb{N}\)</span>,
<span class="math display">\[
\mathbb{P}[X_{n+m} = j \: | \: \mathcal{F}_n] = p^{(m)}(X_n,j),
\]</span>
gdzie <span class="math inline">\((p^{(m)(i,j) })_{i, j \in S}\)</span> jest <span class="math inline">\(m\)</span>-tą potęgą macierzy przejścia
<span class="math display">\[
p^{(m)}(i,j) = \mathbb{P}[X_m=j \: | \: X_0=i].
\]</span>
Oznacza to, że dla dowolnej funkcji mierzalnej <span class="math inline">\(f \colon S \to \mathbb{R}\)</span>,
<span class="math display">\[
\mathbb{E}[ f(X_{n+m}) \: | \: \mathcal{F}_n] = \sum_{s \in S} f(s) p^{(m)}(X_n, s).
\]</span>
Powyższa definicja względnie łatwo zapisuje się w czasie ciągłym
<span class="math display">\[
\mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] = \sum_{x\in S} f(x) p^{(t)}(X_n, x),
\]</span>
gdzie
<span class="math display">\[
p^{(t)}(y,x) = \mathbb{P}[X_t=x | X_0=y].
\]</span>
Relacja powyższa daje się zapisać w przypadku nieprzeliczalnej przestrzeni stanów jako
<span class="math display">\[
\mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] = \int_S f(x) p^{(t)}(X_n, \mathrm{d} x),
\]</span>
gdzie
<span class="math display">\[
p^{(t)}(y, \mathrm{d} x) = \mathbb{P}[X_t \in \mathrm{d} x | X_0=y]
\]</span>
jest rozkładem <span class="math inline">\(X_t\)</span> pod warunkiem <span class="math inline">\(\{X_0=y\}\)</span>. To niesie ze sobą kolejne problemy, ponieważ jak wcześniej zauważyliśmy <span class="math inline">\(\{X_0=y\}\)</span> może być zdarzeniem o prawdopodobieństwie zero. Przedstawione podejście jest do uratowania pod kątem formalnym przez odniesienie się do regularnych rozkładów warunkowych.</p>
<p>Zamiast tego podejdziemy do problemu od innej strony. Naszym punktem wyjścia będzie odpowiednia rodzina miar. Jak zobaczymy wkrótce, to podejście będzie również opierało się o odpowiednik powyższej relacji. Oznacza to, że w rezultacie będziemy opisywali tę samą klasę procesów stochastycznych bez konieczności obchodzenia się z warunkowaniem po zdarzeniach niemożliwych.</p>
<div id="podstawowe-definicje" class="section level2 unnumbered hasAnchor">
<h2>Podstawowe definicje<a href="#podstawowe-definicje" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Zaczynamy od prezentacji definicji trzech obiektów, na których się skupimy w tym rozdziale. Przypomnijmy, że będziemy definiować łańcuchy Markowa w czasie ciągłym na dyskretnej przestrzeni stanów <span class="math inline">\(S\)</span>. Topologia na <span class="math inline">\(S\)</span> to oczywiście topologia dyskretna, względem której wszystkie funkcje są ciągłe.</p>
<p>Głównym obiektem naszych badań będą procesy stochastyczne. Ze względów technicznych pracować będziemy na bardzo konkretnej przestrzeni zdarzeń elementarnych. Niech <span class="math inline">\(\Omega\)</span> będzie zbiorem prawostronnie ciągłych funkcji <span class="math inline">\(\omega \colon [0, \infty) \to S\)</span> ze skończoną liczbą skoków w dowolnym skończonym przedziale czasowym. Dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span> rozważmy funkcję <span class="math inline">\(X_t \colon \Omega \to S\)</span> zadaną przez
<span class="math display">\[
X_t(\omega) = \omega(t).
\]</span>
Niech <span class="math inline">\(\sigma\)</span>-ciało <span class="math inline">\(\mathcal{F}\)</span> na <span class="math inline">\(\Omega\)</span> będzie najmniejszym takim, że odwzorowanie <span class="math inline">\(\omega \mapsto \omega(t)\)</span> jest mierzalne dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span>. Niech wreszcie dla <span class="math inline">\(s \in \mathbb{R}_+\)</span> oznaczmy przez <span class="math inline">\(\theta_s\)</span> odwzorowanie <span class="math inline">\(\Omega \to \Omega\)</span> zadane przez
<span class="math display">\[
\theta_s(\omega)(t) = \omega(t+s).
\]</span>
W szczególności <span class="math inline">\(X_t \circ \theta_s = X_{t+s}\)</span>. O odwzorowaniu <span class="math inline">\(\theta_s\)</span> można myśleć jak o przesunięciu czasu o <span class="math inline">\(s\)</span>. Zamiast utożsamiać własność Markowa z procesem stochastycznym <span class="math inline">\(X=\{X(t)\}_{t \in \mathbb{R}_+}\)</span>, utożsamimy ją z rodziną miar probabilistycznych na <span class="math inline">\(\Omega\)</span>, względem której <span class="math inline">\(X\)</span> będzie procesem Markowa.</p>
<div class="definition">
<p><span id="def:2-1" class="definition"><strong>Definicja 1  </strong></span>Łańcuchem Markowa w czasie ciągłym na przestrzeni stanów <span class="math inline">\(S\)</span> nazywamy parę uporządkowaną
<span class="math inline">\(( \mathbf{P}, \mathbb{F})\)</span> taką, że</p>
<ul>
<li><p><strong>(ŁM1)</strong> <span class="math inline">\(\mathbb{F}=(\mathcal{F}_t)_{t \in \mathbb{R}_+}\)</span> jest filtracją względem której
<span class="math inline">\(X = (X(t))_{t \in \mathbb{R}_+}\)</span> jest adaptowalny i
<span class="math inline">\(\mathcal{F}_t \subseteq \mathcal{F}\)</span> dla każdego <span class="math inline">\(t \in \mathbb{R}_+\)</span>.</p></li>
<li><p><strong>(ŁM2)</strong> <span class="math inline">\(\mathbf{P}= \{ \mathbf{P}_x\}_{x \in S}\)</span>. Dla każdego <span class="math inline">\(x \in S\)</span>, <span class="math inline">\(\mathbf{P}_x\)</span> jest miarą probabilistyczną na <span class="math inline">\(\Omega\)</span> taką, że
<span class="math display">\[
\mathbf{P}_x[X_0 = x] = \mathbf{P}_x[\omega \in \Omega : \omega(0)=x]= 1.
\]</span></p></li>
<li><p><strong>(ŁM3)</strong> Spełniona jest własność Markowa
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s] = \mathbf{E}_{X(s)}[Y] \text{ p.n. } \mathbf{P}_x
\]</span>
dla wszystkich <span class="math inline">\(x \in S\)</span> i wszystkich ograniczonych mierzalnych <span class="math inline">\(Y\)</span> na <span class="math inline">\(\Omega\)</span>.</p></li>
</ul>
</div>
<p>W powyższej definicji <span class="math inline">\(\mathbf{E}_x\)</span> jest wartością oczekiwaną odpowiadającą
mierze probabilistycznej <span class="math inline">\(\mathbf{P}_x\)</span>, czyli
<span class="math display">\[
\mathbf{E}_x[Y] = \int_\Omega Y(\omega) \: \mathbf{P}_x(\mathrm{d} \omega).
\]</span>
O zmiennej losowej <span class="math inline">\(Y \colon \Omega \to \mathbb{R}\)</span>
można myśleć jak o statystyce całej trajektorii procesu
<span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span>. Załóżmy, że <span class="math inline">\(Y\)</span> jest postaci
<span class="math display">\[
Y(\omega) = f(\omega(t_1), \omega(t_2), \ldots , \omega(t_n)) = f(X(t_1), X(t_2), \ldots, X(t_n))
\]</span>
dla pewnej mierzalnej i ograniczonej funkcji <span class="math inline">\(f \colon \mathbb{R}^n \to \mathbb{R}\)</span>
(dla ćwiczenia warto sprawdzić, że <span class="math inline">\(Y\)</span> powyższej postaci jest istotnie zmienną losową, tj. jest mierzalna względem <span class="math inline">\(\mathcal{F}\)</span>).
Wówczas
<span class="math display">\[
Y\circ \theta_s(\omega) = f(\omega(t_1+s), \omega(t_2+s), \ldots , \omega(t_n+s)) = f(X(t_1+s), X(t_2+s), \ldots, X(t_n+s)).
\]</span>
Własność Markowa w Definicji mówi zatem to, co powinna. Rozkład wektora losowego <span class="math inline">\((X(t_1+s), X(t_2+s), \ldots, X(t_n+s))\)</span> pod warunkiem <span class="math inline">\(\mathcal{F}_s\)</span> jest taki sam, jak rozkład wektora <span class="math inline">\((X&#39;(t_1), X&#39;(t_2), \ldots, X&#39;(t_n))\)</span> dla <span class="math inline">\(X&#39;=\{X&#39;(t)\}_{t\in \mathbb{R}_+}\)</span> będącym niezależną kopią <span class="math inline">\(X\)</span>, zapoczątkowaną w <span class="math inline">\(X_0&#39;=X(s)\)</span>.</p>
<p>Naszym nadrzędnym celem będzie sprowadzenie powyższej definicji do bardziej przystępnych terminów. Zanim jednak do tego przejdziemy, rozważmy następujący przykład.</p>
<div class="example">
<p><span id="exm:2-poisson" class="example"><strong>Przykład 1  </strong></span>Niech <span class="math inline">\(N=(N_t)_{t \in \mathbb{R}_+}\)</span> będzie jednorodnym
procesem Poissona z intensywnością <span class="math inline">\(\lambda &gt;0\)</span> określonym na przestrzeni
probabilistycznej <span class="math inline">\((\Sigma, \mathcal{G}, \mathbb{P})\)</span>.
Przypomnijmy, że oznacza to, że <span class="math inline">\(t \mapsto N_t\)</span> jest prawostronnie ciągła oraz
dla każdego <span class="math inline">\(t&gt;0\)</span> zmienna losowa <span class="math inline">\(N_t\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda&gt;0\)</span>,
<span class="math display">\[
\mathbb{P}[N_t=k] = e^{-\lambda} \frac{\lambda^k}{k!},
\]</span>
i wreszcie dla <span class="math inline">\(t&gt;s\geq 0\)</span>, zmienna <span class="math inline">\(N_t - N_s\)</span> jest niezależna
od <span class="math inline">\(\sigma\)</span>-ciała <span class="math inline">\(\mathcal{F}_s^N = \sigma(N_r : r \leq s)\)</span>.</p>
<p>Uzasadnimy, że <span class="math inline">\(N\)</span> jest procesem Markowa w sensie przyjętej przez nas definicji.
Przestrzenią stanów jest <span class="math inline">\(S = \mathbb{N}\)</span>.
Niech <span class="math inline">\(\mathbf{P}_x[A] = \mathbb{P}[N + x \in A]\)</span> dla <span class="math inline">\(A \in \mathcal{F}\)</span>.
Tutaj <span class="math inline">\(x+N\)</span> oznacza funkcję <span class="math inline">\(t \mapsto N_t + x\)</span>.
Pokażemy teraz, że spełniona jest własność Markowa.</p>
<p>Dla <span class="math inline">\(A \in \mathcal{F}_s\)</span> mamy
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[Y(N \circ \theta_s + x) \mathbf{1}_{\{N \in A\}}]
= \mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{\{N \in A\}}].
\]</span>
Skoro <span class="math inline">\(A \in \mathcal{F}_s\)</span>, to <span class="math inline">\(\{N \in A\} \in \mathcal{F}_s^N\)</span> (zadanie).
Skoro <span class="math inline">\(N \circ \theta_s - N_s = (N_{t+s} - N_s)_{t \in \mathbb{R}_+}\)</span>
jest niezależny od <span class="math inline">\(\mathcal{F}_s^N\)</span>, to
<span class="math display">\[
\mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{\{N \in A\}} | \mathcal{F}_s] = \mathbf{1}_{\{N \in A\}} \cdot y(N_s + x),
\]</span>
gdzie
<span class="math display">\[
y(k) = \mathbb{E}[Y(N \circ \theta_s - N_s + k)] = \mathbf{E}_k[Y].
\]</span>
Podsumowując,
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[y(N_s + x) \mathbf{1}_{\{N \in A\}}]
= \mathbf{E}_x[y(X(s)) \mathbf{1}_A]
\]</span>
odwołując się teraz do definicji warunkowej wartości oczekiwanej
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s]
= y(X(s))
= \mathbf{E}_{X(s)}[Y].
\]</span></p>
</div>
<p>Powyższy przykład pokazuje, że uzasadnienie własności Markowa wprost z definicji nie jest najprostszym zadaniem.
Przekonamy się w przyszłości, że taka forma jest przydatna do teoretycznych rozważań.
Mimo to przyda się nam bardziej przystępny sposób mówienia o łańcuchach Markowa w czasie ciągłym.
Odnosząc się do czasu dyskretnego, korzystać będziemy z funkcji przejścia.</p>
<div class="definition">
<p><span id="def:2-2" class="definition"><strong>Definicja 2  </strong></span>Funkcją przejścia nazywamy rodzinę odwzorowań <span class="math inline">\(p = (p_t)_{t \in \mathbb{R}_+}\)</span>,
gdzie <span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zdefiniowanych dla <span class="math inline">\(t \ge 0\)</span> takich, że
<span class="math display">\[
p_t(x, y) \ge 0, \quad \sum_{y \in S} p_t(x, y) = 1, \quad \lim_{t \to 0} p_t(x, x) = p_0(x, x) = 1,
\]</span>
spełniających równania Chapmana-Kolmogorowa
<span class="math display">\[
p_{s+t}(x, y) = \sum_{z \in S} p_s(x, z)p_t(z, y).
\]</span></p>
</div>
<p>Interpretacją wartości <span class="math inline">\(p_t(x,y)\)</span> jest prawdopodobieństwo,
że w czasie <span class="math inline">\(t\)</span> proces przejdzie ze stanu <span class="math inline">\(x\)</span> do stanu <span class="math inline">\(y\)</span>.
Innymi słowy,
<span class="math display">\[
p_t(x,y) = \mathbf{P}_x[X_t = y].
\]</span>
Jak się niebawem przekonamy,
dzięki własności Markowa pozwala ona jednoznacznie wyznaczyć rozkład procesu,
tj. jednoznacznie wyznaczyć miarę <span class="math inline">\(\mathbf{P}_x\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Przykład 2  </strong></span>Rozważmy <span class="math inline">\(S = \mathbb{N}\)</span>, <span class="math inline">\(\lambda &gt; 0\)</span> oraz
<span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zadane przez
<span class="math display">\[
p_t(x, y) = e^{-\lambda t} \frac{(\lambda t)^{y - x}}{(y - x)!} \mathbf{1}_{\{y \geq x\}}.
\]</span>
Wówczas <span class="math inline">\(p\)</span> jest funkcją przejścia.
Wystarczy zauważyć, że <span class="math inline">\(p_t(x)\)</span> to prawdopodobieństwo, że zmienna losowa o
rozkładzie Poissona z parametrem <span class="math inline">\(\lambda t\)</span> jest równa <span class="math inline">\(y - x\)</span>.
Równania Chapmana-Kołmogorowa wynikają z następującej własności rozkładu Poissona:
jeżeli niezależne zmienne losowe <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> mają rozkłady Poissona odpowiednio z
parametrami <span class="math inline">\(\lambda t\)</span> i <span class="math inline">\(\lambda s\)</span>,
to <span class="math inline">\(X + Y\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda (t + s)\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:2-12" class="theorem"><strong>Twierdzenie 1  </strong></span>Dla łańcucha Markowa <span class="math inline">\((\mathbf{P}, \mathbb{F})\)</span> połóżmy
<span class="math display">\[
p_t(x, y) = \mathbf{P}_x[X_t = y]
\]</span>
dla <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x, y \in S\)</span>. Wówczas:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(p_t(x, y)\)</span> jest funkcją przejścia,</p></li>
<li><p><span class="math inline">\(p_t(x, y)\)</span> określa miary <span class="math inline">\(\mathbf{P}_x\)</span> jednoznacznie.</p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li>Najpierw pokażemy, że <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.
Przez prawostronną ciągłość ścieżek,
<span class="math inline">\(\tau = \inf \{ t &gt; 0 : X_t \neq X_0 \} &gt; 0\)</span> <span class="math inline">\(\mathbf{P}_x\)</span>-p.w.
dla dowolnego <span class="math inline">\(x\)</span> z <span class="math inline">\(S\)</span>.
Ponieważ
<span class="math display">\[p_t(x, x) \ge \mathbf{P}_x[\tau &gt; t] \to 1\]</span>
przy <span class="math inline">\(t \to 0\)</span>, to istotnie <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.</li>
</ol>
<p>Równania Chapmana-Kołmogorowa wynikają z własności Markowa.
Aby to zobaczyć, rozważmy <span class="math inline">\(Y = 1_{\{ X(t)=y \}}\)</span>.
Własność Markowa zapisuje się jako
<span class="math display">\[
    \mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s]
    = \mathbf{P}_{X(s)}[X_t = y]
    = p_t(X(s), y) \text{ p.n. } \mathbf{P}_x.
\]</span>
Biorąc wartości oczekiwane względem <span class="math inline">\(\mathbf{P}_x\)</span> w tej tożsamości,
otrzymujemy równania Chapmana-Kołmogorowa:
<span class="math display">\[
    \mathbf{P}_x[X_{t+s}=y]
    = \mathbf{E}_x \left[\mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s] \right]
    = \mathbf{E}_x\left[ p_t(X(s), y) \right]
    = \sum_{z \in S } p_t(z, y) p_s(x, z).
\]</span>
To dowodzi a.
b. Użyjemy własności Markowa wielokrotnie, aby otrzymać
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = p_{t_1}(x, x_1) p_{t_2 - t_1}(x_1, x_2) \cdots p_{t_n - t_{n-1}}(x_{n-1}, x_n)
\]</span>
dla <span class="math inline">\(0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> oraz <span class="math inline">\(x_1, \ldots, x_n \in S\)</span>.
Aby to zobaczyć oznaczmy
<span class="math display">\[
    \mathcal{H}_{n-1} = \{ X(t_1) = x_1, \ldots, X(t_{n-1}) = x_{n-1} \} \in \mathcal{F}_{t_{n-1}}.
\]</span>
Z własności Markowa
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{P}_x[\mathcal{H}_{n-1}, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X \circ \theta_{t_{n-1}} (t_n - t_{n-1}) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_{X(t_{n-1})}[X (t_n - t_{n-1}) = x_n]
    = \mathbf{1}_{\mathcal{H}_{n-1}} p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Biorąc wartości oczekiwane,
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = \mathbf{P}_x[\mathcal{H}_{n-1}] p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Postulowaną równość otrzymujemy przez iterację powyższej procedury.
Udowodniona właśnie równość uzasadnia,
że funkcja przejścia określa rozkłady skończenie wymiarowe <span class="math inline">\(\mathbf{P}_x\)</span>.
Określa również pełną miarę <span class="math inline">\(\mathbf{P}_x\)</span>,
ponieważ miary prawdopodobieństwa na <span class="math inline">\((\Omega, \mathcal{F})\)</span> są określane
przez ich skończenie wymiarowe rozkłady w świetle twierdzenia <span class="math inline">\(\pi - \lambda\)</span>.
Aby to zobaczyć, załóżmy, że <span class="math inline">\(\mu\)</span> oraz <span class="math inline">\(\nu\)</span> to dwie takie miary,
które mają te same skończenie wymiarowe rozkłady,
i niech <span class="math inline">\(\mathcal{P}\)</span> będą skończenie wymiarowymi zbiorami w <span class="math inline">\((\Omega, \mathcal{F})\)</span> oraz
<span class="math display">\[
    \mathcal{L} = \{ A \in \mathcal{F} : \mu(A) = \nu(A) \}.
\]</span>
Wówczas <span class="math inline">\(\mathcal{L}\)</span> jest <span class="math inline">\(\lambda\)</span>-układem zawierającym
<span class="math inline">\(\pi\)</span>-układ <span class="math inline">\(\mathcal{P}\)</span>.
Przez twierdzenie <span class="math inline">\(\pi - \lambda\)</span>,
<span class="math inline">\(\sigma(\mathcal{P}) \subseteq \mathcal{L}\)</span>.
Skoro <span class="math inline">\(\sigma(\mathcal{P}) = \mathcal{F}\)</span>,
to <span class="math inline">\(\mu(A) = \nu(A)\)</span> dla wszystkich <span class="math inline">\(A \in \mathcal{F}\)</span>.</p>
</div>
<p>Skoro <span class="math inline">\(X\)</span> jest elementem <span class="math inline">\(\Omega\)</span>,
zbioru funkcji prawostronnie ciągłych o wartościach w przeliczalnym <span class="math inline">\(S\)</span>,
to <span class="math inline">\(X\)</span> jest funkcją kawałkami stałą.
W rezultacie do opisu <span class="math inline">\(X\)</span> wystarczy sprecyzować,
w jaki sposób <span class="math inline">\(X\)</span> zmienia wartość.
Opis ten jest dokonywany w kategoriach <span class="math inline">\(Q\)</span>-macierzy.</p>
<div class="definition">
<p><span id="def:2-3" class="definition"><strong>Definicja 3  </strong></span><span class="math inline">\(Q\)</span>-macierzą nazywamy macierz <span class="math inline">\((q(x, y))_{x,y \in S}\)</span>
liczb rzeczywistych indeksowanych przez <span class="math inline">\(x, y \in S\)</span>,
które spełniają
<span class="math display">\[
q(x, y) \ge 0 \text{ dla } x \neq y \quad \text{oraz} \quad \sum_y q(x, y) = 0.
\]</span></p>
</div>
<p>Ponieważ wyrazy diagonalne są niedodatnie i
odgrywają specjalną rolę,
naturalne jest użycie specjalnego oznaczenia dla nich:
<span class="math display">\[
c(x) = -q(x, x).
\]</span>
Przejście od funkcji przejścia do <span class="math inline">\(Q\)</span>-macierzy
jest trudniejsze niż przejście od procesu do funkcji przejścia
i wymaga dokonania dodatkowych założeń.
Zaczynamy od kilku własności, które obowiązują dla wszystkich funkcji przejścia.</p>
<div class="theorem">
<p><span id="thm:2-13" class="theorem"><strong>Twierdzenie 2  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Wówczas <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla wszystkich <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x \in S\)</span>.</p></li>
<li><p>Jeśli <span class="math inline">\(p_t(x, x) = 1\)</span> dla pewnego <span class="math inline">\(t &gt; 0\)</span> oraz <span class="math inline">\(x \in S\)</span>, wtedy <span class="math inline">\(p_t(x, x) = 1\)</span> dla wszystkich <span class="math inline">\(t &gt; 0\)</span> oraz tego <span class="math inline">\(x\)</span>.</p></li>
<li><p>Dla każdego <span class="math inline">\(x, y \in S\)</span>, <span class="math inline">\(p_t(x, y)\)</span> jest jednostajnie ciągła w <span class="math inline">\(t\)</span>. Dokładniej,
<span class="math display">\[
   |p_t(x, y) - p_s(x, y)| \leq 1 - p_{|t-s|}(x, x).
\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Najpierw zauważmy, że <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla małych <span class="math inline">\(t\)</span> zgodnie z
przyjętą Definicją <a href="#def:2-2">2</a>
Z równań Chapmana-Kołmogorowa,
<span class="math display">\[
p_{s+t}(x, x) \geq p_s(x, x)p_t(x, x),
\]</span>
więc ścisła dodatniość rozciąga się na wszystkie <span class="math inline">\(t\)</span>.</p></li>
<li><p>Użyjmy równania Chapmana-Kołmogorowa raz jeszcze, aby napisać
<span class="math display">\[
p_{s+t}(x, x) \leq p_s(x, x)p_t(x, x) + [1 - p_s(x, x)] = 1 - p_s(x, x)[1 - p_t(x, x)].
\]</span>
Zatem, jeśli <span class="math inline">\(p_{s+t}(x, x) = 1\)</span>, to <span class="math inline">\(p_t(x, x) = 1\)</span>,
ponieważ <span class="math inline">\(p_s(x, x) &gt; 0\)</span> z części a.
Stąd <span class="math inline">\(\{ t \ge 0 : p_t(x, x) = 1 \}\)</span> jest przedziałem zaczynającym się od 0.
Z dowodu części a. wynika, że musi to być cała dodatnia oś.</p></li>
<li><p>Ponownie użyjmy równania Chapmana-Kołmogorowa,
aby napisać
<span class="math display">\[
p_{t+s}(x, y) - p_t(x, y) = p_t(x, y)[p_s(x, x) - 1] + \sum_{z \neq x} p_s(x, z)p_t(z, y).
\]</span>
Pierwszy składnik po prawej stronie jest niedodatni,
a drugi jest nieujemny. Wartość bezwzględna każdego z nich nie jest większa niż <span class="math inline">\(1 - p_s(x, x)\)</span>.
To pociąga postulowaną nierówność, która z kolei pociąga jednostajną ciągłość.</p></li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:2-14" class="theorem"><strong>Twierdzenie 3  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Dla każdego <span class="math inline">\(x\)</span>, prawostronna pochodna
<span class="math display">\[
     c(x) = -q(x, x) = - \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, x) \right|_{t=0} \in [0, \infty]
\]</span>
istnieje i spełnia
<span class="math display">\[
     p_t(x, x) \ge e^{-c(x)t}.
\]</span></p></li>
<li><p>Jeśli <span class="math inline">\(c(x) &lt; \infty\)</span>, wtedy dla tego <span class="math inline">\(x\)</span> i dla wszystkich <span class="math inline">\(y \neq x\)</span>, prawostronna pochodna
<span class="math display">\[
     q(x, y) = \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) \right|_{t=0} \in [0, \infty)
\]</span>
istnieje oraz
<span class="math display">\[
     \sum_{y \in S} q(x, y) \leq 0.
\]</span></p></li>
<li><p>Jeśli dla pewnego <span class="math inline">\(x \in S\)</span>,
<span class="math inline">\(c(x) &lt; \infty\)</span> i <span class="math inline">\(\sum_y q(x, y) = 0\)</span>, to <span class="math inline">\(p_t(x, y)\)</span>
jest różniczkowalna w sposób ciągły względem <span class="math inline">\(t\)</span> dla tego <span class="math inline">\(x\)</span> i każdego <span class="math inline">\(y\)</span>,
oraz spełnia równania retrospektywne Kołmogorowa:
<span class="math display">\[
     \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) = \sum_z q(x, z)p_t(z, y).
\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Niech <span class="math inline">\(f(t) = - \log p_t(x, x)\)</span>.
Wówczas <span class="math inline">\(f\)</span> jest dobrze określona i jednostajnie ciągła.
Jest ona też subaddytywna.
Zatem, zgodnie z Lematem Fekete,
<span class="math display">\[
c(x) = \lim_{t \to 0} \frac{f(t)}{t} \in [0, \infty]
\]</span>
i spełnia <span class="math inline">\(f(t) \leq c(x)t\)</span>.</p></li>
<li><p>Przypuśćmy, że <span class="math inline">\(c(x) &lt; \infty\)</span>. Z dowiedzionej właśnie nierówności,
<span class="math display">\[
1 - p_t(x, x) \leq 1 - e^{-c(x)t} \leq c(x)t,
\]</span>
i stąd
<span class="math display">\[
\sum_{y : y \neq x} \frac{p_t(x, y)}{t} \leq c(x).
\]</span>
Zatem,
<span class="math display" id="eq:2-1">\[
\limsup_{t \to 0} \frac{p_t(x, y)}{t} &lt; \infty
\tag{1}
\]</span>
dla <span class="math inline">\(y \neq x\)</span>.
Niech <span class="math inline">\(q(x, y)\)</span> będzie wartością powyższej granicy górnej.
Aby pokazać, że granica rzeczywiście istnieje,
weźmy <span class="math inline">\(\delta &gt; 0\)</span> i dodatnią liczbę całkowitą <span class="math inline">\(n\)</span>.
Macierz <span class="math inline">\(p_{\delta}(x, y)\)</span> można traktować jako prawdopodobieństwa
przejścia dla dyskretnego łańcucha Markowa na <span class="math inline">\(S\)</span>,
a wtedy zgodnie z równaniami Chapmana-Kołmogorowa,
odpowiadające <span class="math inline">\(n\)</span>-krokowe prawdopodobieństwa przejścia są dane przez <span class="math inline">\(p_{n\delta}(x, y)\)</span>.
Rozkładając zdarzenie,
że ten łańcuch znajduje się w <span class="math inline">\(y\)</span> w czasie <span class="math inline">\(n\)</span>
zgodnie z czasem pierwszej wizyty w <span class="math inline">\(y\)</span>, mamy dla <span class="math inline">\(y \neq x\)</span>,
<span class="math display">\[
p_{n\delta}(x, y) \geq \sum_{k=0}^{n-1} p_{k\delta}^k(x, x) p_{\delta}(x, y)p_{(n-k-1)\delta}(y, y).
\]</span>
Stąd
<span class="math display">\[
\frac{p_{n\delta}(x, y)}{n\delta}
\geq \frac{p_{\delta}(x, y)}{\delta} e^{-c(x)n\delta} \inf_{0 \leq s \leq n\delta} p_s(y, y).
\]</span>
Teraz niech <span class="math inline">\(\delta \downarrow 0\)</span> wzdłuż
ciągu realizującego granicę górną w <a href="#eq:2-1">(1)</a>, tak że
<span class="math display">\[
\frac{p_{\delta}(x, y)}{\delta} \to q(x, y).
\]</span>
Wybierzmy teraz <span class="math inline">\(n \to \infty\)</span> tak, że <span class="math inline">\(n\delta \to t\)</span>. Wówczas
<span class="math display">\[
\frac{p_t(x, y)}{t} \geq q(x, y)e^{-c(x)t} \inf_{0 \leq s \leq t} p_s(y, y)
\]</span>
dla <span class="math inline">\(t &gt; 0\)</span>. Zatem,
<span class="math display">\[
\liminf_{t \to 0} \frac{p_t(x, y)}{t} \geq q(x, y).
\]</span>
Postulowana nierówność wynika teraz z lematu Fatou.</p></li>
<li><p>Napiszmy
<span class="math display">\[
\frac{p_{t+s}(x, y) - p_t(x, y)}{s} = \sum_z \left[ \frac{p_s(x, z) - p_0(x, z)}{s} - q(x, z) \right] p_t(z, y).
\]</span>
Każdy wyraz w sumie dąży do <span class="math inline">\(0\)</span>, gdy <span class="math inline">\(s \downarrow 0\)</span>,
zgodnie z pierwszymi dwoma częściami twierdzenia.
Zatem musimy kontrolować ogony sumy.
Weźmy skończony zbiór <span class="math inline">\(T \subset S\)</span> zawierający <span class="math inline">\(x\)</span> i zauważmy, że
<span class="math display">\[
\sum_{z \notin T} \left| \frac{p_s(x, z)}{s} - q(x, z) \right| p_t(z, y) \leq \sum_{z \notin T} \frac{p_s(x, z)}{s} + \sum_{z \notin T} q(x, z)
\]</span>
<span class="math display">\[
= s^{-1} \left[ 1 - \sum_{z \in T} p_s(x, z) \right] - \sum_{z \in T} q(x, z) \to -2 \sum_{z \in T} q(x, z)
\]</span>
gdy <span class="math inline">\(s \downarrow 0\)</span>.
Granicę po prawej stronie można uczynić dowolnie małą,
wybierając <span class="math inline">\(T\)</span> duże, ponieważ <span class="math inline">\(\sum_z q(x, z) = 0\)</span>.
Zatem prawa strona dąży do zera,
gdy <span class="math inline">\(s \downarrow 0\)</span>. To dowodzi, że prawostronne pochodne <span class="math inline">\(p_t(x, y)\)</span>
istnieją i spełniają zadaną równość.
Aby zobaczyć, że obustronne pochodne rzeczywiście istnieją,
wystarczy zauważyć, że prawa strona jest ciągła w <span class="math inline">\(t\)</span> i użyć faktu,
że funkcja ciągła z ciągłą prawostronną pochodną jest różniczkowalna.</p></li>
</ol>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SMUO_wyklad1.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
