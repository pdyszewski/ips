<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Wykład 1: Łańcuchy Markowa w czasie ciągłym | Stochastyczne modele układów oddziałujących 2024</title>
<meta name="author" content="Piotr Dyszewski">
<meta name="description" content="2024-10-03 Piotr Dyszewski Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie ciągłym na przeliczalnym (lub skończonym) zbiorze \(S\) w oparciu o jego opis infinitezymalny. W...">
<meta name="generator" content="bookdown 0.41 with bs4_book()">
<meta property="og:title" content="Wykład 1: Łańcuchy Markowa w czasie ciągłym | Stochastyczne modele układów oddziałujących 2024">
<meta property="og:type" content="book">
<meta property="og:image" content="/cover.png">
<meta property="og:description" content="2024-10-03 Piotr Dyszewski Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie ciągłym na przeliczalnym (lub skończonym) zbiorze \(S\) w oparciu o jego opis infinitezymalny. W...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wykład 1: Łańcuchy Markowa w czasie ciągłym | Stochastyczne modele układów oddziałujących 2024">
<meta name="twitter:description" content="2024-10-03 Piotr Dyszewski Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie ciągłym na przeliczalnym (lub skończonym) zbiorze \(S\) w oparciu o jego opis infinitezymalny. W...">
<meta name="twitter:image" content="/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="test.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Notatni do wykładu">Stochastyczne modele układów oddziałujących 2024</a>:
        <small class="text-muted">Notatni do wykładu</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Stochastyczne modele układów oddziałujących</a></li>
<li><a class="" href="sylabus.html">Sylabus</a></li>
<li><a class="active" href="wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym.html">Wykład 1: Łańcuchy Markowa w czasie ciągłym</a></li>
<li><a class="" href="wyk%C5%82ad-2-mocna-w%C5%82asno%C5%9B%C4%87-markowa.html">Wykład 2: Mocna własność Markowa</a></li>
<li><a class="" href="wyk%C5%82ad-3-procesy-i-p%C3%B3%C5%82grupy-fellera.html">Wykład 3: procesy i półgrupy Fellera</a></li>
<li><a class="" href="wyk%C5%82ad-4-generatory.html">Wykład 4: Generatory</a></li>
<li><a class="" href="wyk%C5%82ad-5-od-generatora-do-p%C3%B3%C5%82grupy.html">Wykład 5: od generatora do półgrupy</a></li>
<li><a class="" href="wyk%C5%82ad-6-od-generatora-przez-p%C3%B3%C5%82grup%C4%99-do-procesu.html">Wykład 6: od generatora przez półgrupę do procesu</a></li>
<li><a class="" href="wyk%C5%82ad-7-rozk%C5%82ady-stacjonarne-zaburzenia-ruchu-browna.html">Wykład 7: Rozkłady stacjonarne, zaburzenia ruchu Browna</a></li>
<li><a class="" href="wyk%C5%82ad-8-uk%C5%82ady-spinowe.html">Wykład 8: Układy spinowe</a></li>
<li><a class="" href="wyk%C5%82ad-9-konstrukcja-system%C3%B3w-spinowych.html">wykład 9: Konstrukcja systemów spinowych</a></li>
<li><a class="" href="wyk%C5%82ad-10-procesy-dualne.html">Wykład 10: Procesy dualne</a></li>
<li><a class="" href="wyk%C5%82ad-11-the-voter-model-przypadek-rekurencyjny.html">Wykład 11: The voter model: przypadek rekurencyjny</a></li>
<li><a class="" href="wyk%C5%82ad-12-the-voter-model-przypadek-tranzytywny.html">Wykład 12: The voter model: przypadek tranzytywny</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="wykład-1-łańcuchy-markowa-w-czasie-ciągłym" class="section level1 unnumbered">
<h1>Wykład 1: Łańcuchy Markowa w czasie ciągłym<a class="anchor" aria-label="anchor" href="#wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym"><i class="fas fa-link"></i></a>
</h1>
<p>2024-10-03</p>
<p><em>Piotr Dyszewski</em></p>
<p>Celem tego rozdziału jest skonstruowanie procesów Markowa w czasie ciągłym na przeliczalnym (lub skończonym)
zbiorze <span class="math inline">\(S\)</span> w oparciu o jego opis infinitezymalny. W następnym rozdziale zbadamy problem konstrukcji dla procesów
na bardziej ogólnej przestrzeni stanów.
Na razie ograniczamy naszą uwagę do bardziej konkretnej sytuacji przeliczalnego <span class="math inline">\(S\)</span>.
W tym przypadku często używa się słowa “łańcuch” zamiast “proces”. clcl</p>
<p>Przypomnijmy, że łańcuchem Markowa w czasie dyskretnym nazywamy proces stochastyczny
<span class="math inline">\(\{X_n\}_{n \in \mathbb{N}}\)</span> takie, że dla dowolnego <span class="math inline">\(n \in \mathbb{N}\)</span> i
dowolnych <span class="math inline">\(s_0, s_1, \ldots, s_n \in S\)</span> takich, że
<span class="math display">\[
\mathbb{P}\left[ X_{n-1}=s_{n-1}, \: X_{n-2}=s_{n-2}, \ldots , X_0=s_0 \right]&gt;0
\]</span>
zachodzi
<span class="math display">\[
\mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1}, \:  \ldots , X_0=s_0 \right]=
\mathbb{P}\left[ X_n=s_n \: | \: X_{n-1}=s_{n-1} \right].
\]</span>
Powyższa własność jest bardzo często przytaczana jako wyjściowa definicja łańcucha Markowa. Mimo swojej prostoty, która ułatwia czytelnikom pierwsze zetknięcie z własnością Markowa, własność ta ma jedną wadę, która ujawnia się przy bardziej zaawansowanych rozważaniach teoretycznych.</p>
<p>Jeżeli chcemy badać tylko procesy na <strong>przeliczalnej</strong> przestrzeni stanów, to jedno naturalne uogólnienie ma następującą formę. Proces stochastyczny w czasie ciągłym <span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span> nazwiemy łańcuchem Markowa w czasie ciągłym na przeliczalnej przestrzeni stanów <span class="math inline">\(S\)</span>, jeżeli dla dowolnego <span class="math inline">\(n\)</span> i dowolnych <span class="math inline">\(0 \leq t_0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> i dowolnych <span class="math inline">\(s_0, s_1, \ldots, s_n \in S\)</span> takich, że
<span class="math display">\[
\mathbb{P}\left[ X(t_{n-1})=s_{n-1}, \: X(t_{n-2})=s_{n-2}, \ldots , X(t_0)=s_0 \right]&gt;0
\]</span>
zachodzi
<span class="math display">\[\begin{multline*}
\mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1}, \: X(t_{n-2})=s_{n-2}, \ldots , X(t_0)=s_0 \right]\\=
\mathbb{P}\left[ X(t_n)=s_n \: | \: X(t_{n-1})=s_{n-1} \right].
\end{multline*}\]</span>
Powyższa własność nie jest zbyt przydatna, jeżeli chcemy badać procesy na nieprzeliczalnej przestrzeni stanów. Dla bardzo wielu naturalnych obiektów zmienne losowe <span class="math inline">\(X(t)\)</span> w badanym przez nas procesie mogą mieć rozkład ciągły. Oznacza to, że warunek powyższy nie jest spełniony dla dowolnego wyboru parametrów.</p>
<p>W celu znalezienia bardziej elastycznego warunku zauważmy,
że własność Markowa dla jednorodnego łańcucha Markowa
<span class="math inline">\(\{X_n\}_{n \in \mathbb{N}}\)</span> w czasie dyskretnym z macierzą przejścia
<span class="math display">\[
p(i,j) = \mathbb{P}[X_1=j \: | \: X_0=i]
\]</span>
zapisuje się jako
<span class="math display">\[
\mathbb{P}[X_n = j \: | \: \mathcal{F}_n] = p(X_n,j),
\]</span>
gdzie <span class="math inline">\(\mathcal{F}_n = \sigma(X_0, X_1, \ldots, X_n)\)</span>.
Dokładne uzasadnienie powyższej własności pozostawiamy jako zadanie.
Podobnie, dla dowolnego <span class="math inline">\(m \in \mathbb{N}\)</span>,
<span class="math display">\[
\mathbb{P}[X_{n+m} = j \: | \: \mathcal{F}_n] = p^{(m)}(X_n,j),
\]</span>
gdzie <span class="math inline">\((p^{(m)(i,j) })_{i, j \in S}\)</span> jest <span class="math inline">\(m\)</span>-tą potęgą macierzy przejścia
<span class="math display">\[
p^{(m)}(i,j) = \mathbb{P}[X_m=j \: | \: X_0=i].
\]</span>
Oznacza to, że dla dowolnej funkcji mierzalnej <span class="math inline">\(f \colon S \to \mathbb{R}\)</span>,
<span class="math display">\[
\mathbb{E}[ f(X_{n+m}) \: | \: \mathcal{F}_n] = \sum_{s \in S} f(s) p^{(m)}(X_n, s).
\]</span>
Powyższa definicja względnie łatwo zapisuje się w czasie ciągłym
<span class="math display">\[
\mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] = \sum_{x\in S} f(x) p^{(t)}(X_n, x),
\]</span>
gdzie
<span class="math display">\[
p^{(t)}(y,x) = \mathbb{P}[X_t=x | X_0=y].
\]</span>
Relacja powyższa daje się zapisać w przypadku nieprzeliczalnej przestrzeni stanów jako
<span class="math display">\[\begin{equation*}
\mathbb{E}[ f(X_{s+t}) \: | \: \mathcal{F}_s] = \int_S f(x) p^{(t)}(X_n, \mathrm{d} x),
\end{equation*}\]</span>
gdzie
<span class="math display">\[\begin{equation*}
p^{(t)}(y, \mathrm{d} x) = \mathbb{P}[X_t \in \mathrm{d} x | X_0=y]
\end{equation*}\]</span>
jest rozkładem <span class="math inline">\(X_t\)</span> pod warunkiem <span class="math inline">\(\{X_0=y\}\)</span>. To niesie ze sobą kolejne problemy, ponieważ jak wcześniej zauważyliśmy <span class="math inline">\(\{X_0=y\}\)</span> może być zdarzeniem o prawdopodobieństwie zero. Przedstawione podejście jest do uratowania pod kątem formalnym przez odniesienie się do regularnych rozkładów warunkowych.</p>
<p>Zamiast tego podejdziemy do problemu od innej strony. Naszym punktem wyjścia będzie odpowiednia rodzina miar. Jak zobaczymy wkrótce, to podejście będzie również opierało się o odpowiednik powyższej relacji. Oznacza to, że w rezultacie będziemy opisywali tę samą klasę procesów stochastycznych bez konieczności obchodzenia się z warunkowaniem po zdarzeniach niemożliwych.</p>
<div id="podstawowe-definicje" class="section level2 unnumbered">
<h2>Podstawowe definicje<a class="anchor" aria-label="anchor" href="#podstawowe-definicje"><i class="fas fa-link"></i></a>
</h2>
<p>Zaczynamy od prezentacji definicji trzech obiektów, na których się skupimy w tym rozdziale. Przypomnijmy, że będziemy definiować łańcuchy Markowa w czasie ciągłym na dyskretnej przestrzeni stanów <span class="math inline">\(S\)</span>. Topologia na <span class="math inline">\(S\)</span> to oczywiście topologia dyskretna, względem której wszystkie funkcje są ciągłe.</p>
<p>Głównym obiektem naszych badań będą procesy stochastyczne. Ze względów technicznych pracować będziemy na bardzo konkretnej przestrzeni zdarzeń elementarnych. Niech <span class="math inline">\(\Omega\)</span> będzie zbiorem prawostronnie ciągłych funkcji <span class="math inline">\(\omega \colon [0, \infty) \to S\)</span> ze skończoną liczbą skoków w dowolnym skończonym przedziale czasowym.</p>
<div class="inline-figure"><img src="StochastyczneModeleUkladowOddzialujacych2024_files/figure-html/r-continuous-function-1.png" width="672"></div>
<pre><code>## List of 1
##  $ plot.margin: 'margin' num [1:4] 0mm 25mm 0mm 0mm
##   ..- attr(*, "unit")= int 7
##  - attr(*, "class")= chr [1:2] "theme" "gg"
##  - attr(*, "complete")= logi FALSE
##  - attr(*, "validate")= logi TRUE</code></pre>
<p>Dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span> rozważmy funkcję <span class="math inline">\(X_t \colon \Omega \to S\)</span> zadaną przez
<span class="math display">\[
X_t(\omega) = \omega(t).
\]</span>
Niech <span class="math inline">\(\sigma\)</span>-ciało <span class="math inline">\(\mathcal{F}\)</span> na <span class="math inline">\(\Omega\)</span> będzie najmniejszym takim, że odwzorowanie <span class="math inline">\(\omega \mapsto \omega(t)\)</span> jest mierzalne dla każdego <span class="math inline">\(t \in \mathbb{R}_+ = [0, +\infty)\)</span>. Niech wreszcie dla <span class="math inline">\(s \in \mathbb{R}_+\)</span> oznaczmy przez <span class="math inline">\(\theta_s\)</span> odwzorowanie <span class="math inline">\(\Omega \to \Omega\)</span> zadane przez
<span class="math display">\[
\theta_s(\omega)(t) = \omega(t+s).
\]</span>
W szczególności <span class="math inline">\(X_t \circ \theta_s = X_{t+s}\)</span>. O odwzorowaniu <span class="math inline">\(\theta_s\)</span> można myśleć jak o przesunięciu czasu o <span class="math inline">\(s\)</span>. Zamiast utożsamiać własność Markowa z procesem stochastycznym <span class="math inline">\(X=\{X(t)\}_{t \in \mathbb{R}_+}\)</span>, utożsamimy ją z rodziną miar probabilistycznych na <span class="math inline">\(\Omega\)</span>, względem której <span class="math inline">\(X\)</span> będzie procesem Markowa.</p>
<div class="definition">
<p><span id="def:2-1" class="definition"><strong>Definicja 1  </strong></span>Łańcuchem Markowa w czasie ciągłym na przestrzeni stanów <span class="math inline">\(S\)</span> nazywamy parę uporządkowaną
<span class="math inline">\(( \mathbf{P}, \mathbb{F})\)</span> taką, że</p>
<ul>
<li><p><strong>(ŁM1)</strong> <span class="math inline">\(\mathbb{F}=(\mathcal{F}_t)_{t \in \mathbb{R}_+}\)</span> jest filtracją względem której
<span class="math inline">\(X = (X(t))_{t \in \mathbb{R}_+}\)</span> jest adaptowalny i
<span class="math inline">\(\mathcal{F}_t \subseteq \mathcal{F}\)</span> dla każdego <span class="math inline">\(t \in \mathbb{R}_+\)</span>.</p></li>
<li><p><strong>(ŁM2)</strong> <span class="math inline">\(\mathbf{P}= \{ \mathbf{P}_x\}_{x \in S}\)</span>. Dla każdego <span class="math inline">\(x \in S\)</span>, <span class="math inline">\(\mathbf{P}_x\)</span> jest miarą probabilistyczną na <span class="math inline">\(\Omega\)</span> taką, że
<span class="math display">\[
\mathbf{P}_x[X_0 = x] = \mathbf{P}_x[\omega \in \Omega : \omega(0)=x]= 1.
\]</span></p></li>
<li><p><strong>(ŁM3)</strong> Spełniona jest własność Markowa
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s] = \mathbf{E}_{X(s)}[Y] \text{ p.n. } \mathbf{P}_x
\]</span>
dla wszystkich <span class="math inline">\(x \in S\)</span> i wszystkich ograniczonych mierzalnych <span class="math inline">\(Y\)</span> na <span class="math inline">\(\Omega\)</span>.</p></li>
</ul>
</div>
<p>W powyższej definicji <span class="math inline">\(\mathbf{E}_x\)</span> jest wartością oczekiwaną odpowiadającą
mierze probabilistycznej <span class="math inline">\(\mathbf{P}_x\)</span>, czyli
<span class="math display">\[
\mathbf{E}_x[Y] = \int_\Omega Y(\omega) \: \mathbf{P}_x(\mathrm{d} \omega).
\]</span>
O zmiennej losowej <span class="math inline">\(Y \colon \Omega \to \mathbb{R}\)</span>
można myśleć jak o statystyce całej trajektorii procesu
<span class="math inline">\(\{X(t)\}_{t \in \mathbb{R}_+}\)</span>. Załóżmy, że <span class="math inline">\(Y\)</span> jest postaci
<span class="math display">\[
Y(\omega) = f(\omega(t_1), \omega(t_2), \ldots , \omega(t_n)) = f(X(t_1), X(t_2), \ldots, X(t_n))
\]</span>
dla pewnej mierzalnej i ograniczonej funkcji <span class="math inline">\(f \colon \mathbb{R}^n \to \mathbb{R}\)</span>
(dla ćwiczenia warto sprawdzić, że <span class="math inline">\(Y\)</span> powyższej postaci jest istotnie zmienną losową, tj. jest mierzalna względem <span class="math inline">\(\mathcal{F}\)</span>).
Wówczas
<span class="math display">\[\begin{multline*}
Y\circ \theta_s(\omega) = f(\omega(t_1+s), \omega(t_2+s), \ldots , \omega(t_n+s)) \\= f(X(t_1+s), X(t_2+s), \ldots, X(t_n+s)).
\end{multline*}\]</span>
Własność Markowa w Definicji mówi zatem to, co powinna. Rozkład wektora losowego <span class="math inline">\((X(t_1+s), X(t_2+s), \ldots, X(t_n+s))\)</span> pod warunkiem <span class="math inline">\(\mathcal{F}_s\)</span> jest taki sam, jak rozkład wektora <span class="math inline">\((X'(t_1), X'(t_2), \ldots, X'(t_n))\)</span> dla <span class="math inline">\(X'=\{X'(t)\}_{t\in \mathbb{R}_+}\)</span> będącym niezależną kopią <span class="math inline">\(X\)</span>, zapoczątkowaną w <span class="math inline">\(X_0'=X(s)\)</span>.</p>
<p>Naszym nadrzędnym celem będzie sprowadzenie powyższej definicji do bardziej przystępnych terminów. Zanim jednak do tego przejdziemy, rozważmy następujący przykład.</p>
<div class="example">
<p><span id="exm:2-poisson" class="example"><strong>Przykład 1  </strong></span>Niech <span class="math inline">\(N=(N_t)_{t \in \mathbb{R}_+}\)</span> będzie jednorodnym
procesem Poissona z intensywnością <span class="math inline">\(\lambda &gt;0\)</span> określonym na przestrzeni
probabilistycznej <span class="math inline">\((\Sigma, \mathcal{G}, \mathbb{P})\)</span>.
Przypomnijmy, że oznacza to, że <span class="math inline">\(t \mapsto N_t\)</span> jest prawostronnie ciągła oraz
dla każdego <span class="math inline">\(t&gt;0\)</span> zmienna losowa <span class="math inline">\(N_t\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda&gt;0\)</span>,
<span class="math display">\[
\mathbb{P}[N_t=k] = e^{-\lambda} \frac{\lambda^k}{k!},
\]</span>
i wreszcie dla <span class="math inline">\(t&gt;s\geq 0\)</span>, zmienna <span class="math inline">\(N_t - N_s\)</span> jest niezależna
od <span class="math inline">\(\sigma\)</span>-ciała <span class="math inline">\(\mathcal{F}_s^N = \sigma(N_r : r \leq s)\)</span>.</p>
<script src="JAVA/poisson.js"></script><div id="p5-container-poisson">
Parametr lambda w procesie Poissona jest odpowiedzialny za tempo jego wzroztu. Dla małych wartości parametru lambda,
odstępy między skokami są duże i proces porusza się wolno. Dla dużych wartości parametru lambda odstępy są mniejsze i proces prosusza się szybciej.
Za pomocą poniższego suwaka możesz ustawić waretość parametru lambda w zakresie od 0.1 do 1.
<div id="p5-container-poisson-slider">

</div>
</div>
<p>Uzasadnimy, że <span class="math inline">\(N\)</span> jest procesem Markowa w sensie przyjętej przez nas definicji.
Przestrzenią stanów jest <span class="math inline">\(S = \mathbb{N}\)</span>.
Niech <span class="math inline">\(\mathbf{P}_x[A] = \mathbb{P}[N + x \in A]\)</span> dla <span class="math inline">\(A \in \mathcal{F}\)</span>.
Tutaj <span class="math inline">\(x+N\)</span> oznacza funkcję <span class="math inline">\(t \mapsto N_t + x\)</span>.
Pokażemy teraz, że spełniona jest własność Markowa.</p>
<p>Dla <span class="math inline">\(A \in \mathcal{F}_s\)</span> mamy
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[Y(N \circ \theta_s + x) \mathbf{1}_{\{N \in A\}}]
= \mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{\{N \in A\}}].
\]</span>
Skoro <span class="math inline">\(A \in \mathcal{F}_s\)</span>, to <span class="math inline">\(\{N \in A\} \in \mathcal{F}_s^N\)</span> (zadanie).
Skoro <span class="math inline">\(N \circ \theta_s - N_s = (N_{t+s} - N_s)_{t \in \mathbb{R}_+}\)</span>
jest niezależny od <span class="math inline">\(\mathcal{F}_s^N\)</span>, to
<span class="math display">\[
\mathbb{E}[Y(N \circ \theta_s - N_s + N_s + x) \mathbf{1}_{\{N \in A\}} | \mathcal{F}_s] = \mathbf{1}_{\{N \in A\}} \cdot y(N_s + x),
\]</span>
gdzie
<span class="math display">\[
y(k) = \mathbb{E}[Y(N \circ \theta_s - N_s + k)] = \mathbf{E}_k[Y].
\]</span>
Podsumowując,
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s \cdot \mathbf{1}_{A}]
= \mathbb{E}[y(N_s + x) \mathbf{1}_{\{N \in A\}}]
= \mathbf{E}_x[y(X(s)) \mathbf{1}_A]
\]</span>
odwołując się teraz do definicji warunkowej wartości oczekiwanej
<span class="math display">\[
\mathbf{E}_x[Y \circ \theta_s | \mathcal{F}_s]
= y(X(s))
= \mathbf{E}_{X(s)}[Y].
\]</span></p>
</div>
<p>Powyższy przykład pokazuje, że uzasadnienie własności Markowa wprost z definicji nie jest najprostszym zadaniem.
Przekonamy się w przyszłości, że taka forma jest przydatna do teoretycznych rozważań.
Mimo to przyda się nam bardziej przystępny sposób mówienia o łańcuchach Markowa w czasie ciągłym.
Odnosząc się do czasu dyskretnego, korzystać będziemy z funkcji przejścia.</p>
<div class="definition">
<p><span id="def:2-2" class="definition"><strong>Definicja 2  </strong></span>Funkcją przejścia nazywamy rodzinę odwzorowań <span class="math inline">\(p = (p_t)_{t \in \mathbb{R}_+}\)</span>,
gdzie <span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zdefiniowanych dla <span class="math inline">\(t \ge 0\)</span> takich, że
<span class="math display">\[
p_t(x, y) \ge 0, \quad \sum_{y \in S} p_t(x, y) = 1, \quad \lim_{t \to 0} p_t(x, x) = p_0(x, x) = 1,
\]</span>
spełniających równania Chapmana-Kolmogorowa
<span class="math display">\[
p_{s+t}(x, y) = \sum_{z \in S} p_s(x, z)p_t(z, y).
\]</span></p>
</div>
<p>Interpretacją wartości <span class="math inline">\(p_t(x,y)\)</span> jest prawdopodobieństwo,
że w czasie <span class="math inline">\(t\)</span> proces przejdzie ze stanu <span class="math inline">\(x\)</span> do stanu <span class="math inline">\(y\)</span>.
Innymi słowy,
<span class="math display">\[
p_t(x,y) = \mathbf{P}_x[X_t = y].
\]</span>
Jak się niebawem przekonamy,
dzięki własności Markowa pozwala ona jednoznacznie wyznaczyć rozkład procesu,
tj. jednoznacznie wyznaczyć miarę <span class="math inline">\(\mathbf{P}_x\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Przykład 2  </strong></span>Rozważmy <span class="math inline">\(S = \mathbb{N}\)</span>, <span class="math inline">\(\lambda &gt; 0\)</span> oraz
<span class="math inline">\(p_t \colon S \times S \to [0,1]\)</span> zadane przez
<span class="math display">\[
p_t(x, y) = e^{-\lambda t} \frac{(\lambda t)^{y - x}}{(y - x)!} \mathbf{1}_{\{y \geq x\}}.
\]</span>
Wówczas <span class="math inline">\(p\)</span> jest funkcją przejścia.
Wystarczy zauważyć, że <span class="math inline">\(p_t(x)\)</span> to prawdopodobieństwo, że zmienna losowa o
rozkładzie Poissona z parametrem <span class="math inline">\(\lambda t\)</span> jest równa <span class="math inline">\(y - x\)</span>.
Równania Chapmana-Kołmogorowa wynikają z następującej własności rozkładu Poissona:
jeżeli niezależne zmienne losowe <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> mają rozkłady Poissona odpowiednio z
parametrami <span class="math inline">\(\lambda t\)</span> i <span class="math inline">\(\lambda s\)</span>,
to <span class="math inline">\(X + Y\)</span> ma rozkład Poissona z parametrem <span class="math inline">\(\lambda (t + s)\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:2-12" class="theorem"><strong>Twierdzenie 1  </strong></span>Dla łańcucha Markowa <span class="math inline">\((\mathbf{P}, \mathbb{F})\)</span> połóżmy
<span class="math display">\[
p_t(x, y) = \mathbf{P}_x[X_t = y]
\]</span>
dla <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x, y \in S\)</span>. Wówczas:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(p_t(x, y)\)</span> jest funkcją przejścia,</p></li>
<li><p><span class="math inline">\(p_t(x, y)\)</span> określa miary <span class="math inline">\(\mathbf{P}_x\)</span> jednoznacznie.</p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li>Najpierw pokażemy, że <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.
Przez prawostronną ciągłość ścieżek,
<span class="math inline">\(\tau = \inf \{ t &gt; 0 : X_t \neq X_0 \} &gt; 0\)</span> <span class="math inline">\(\mathbf{P}_x\)</span>-p.w.
dla dowolnego <span class="math inline">\(x\)</span> z <span class="math inline">\(S\)</span>.
Ponieważ
<span class="math display">\[p_t(x, x) \ge \mathbf{P}_x[\tau &gt; t] \to 1\]</span>
przy <span class="math inline">\(t \to 0\)</span>, to istotnie <span class="math inline">\(\lim_{t \to 0} p_t(x, x) = 1\)</span>.</li>
</ol>
<p>Równania Chapmana-Kołmogorowa wynikają z własności Markowa.
Aby to zobaczyć, rozważmy <span class="math inline">\(Y = 1_{\{ X(t)=y \}}\)</span>.
Własność Markowa zapisuje się jako
<span class="math display">\[
    \mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s]
    = \mathbf{P}_{X(s)}[X_t = y]
    = p_t(X(s), y) \text{ p.n. } \mathbf{P}_x.
\]</span>
Biorąc wartości oczekiwane względem <span class="math inline">\(\mathbf{P}_x\)</span> w tej tożsamości,
otrzymujemy równania Chapmana-Kołmogorowa:
<span class="math display">\[
    \mathbf{P}_x[X_{t+s}=y]
    = \mathbf{E}_x \left[\mathbf{P}_x[X_{s+t} = y | \mathcal{F}_s] \right]
    = \mathbf{E}_x\left[ p_t(X(s), y) \right]
    = \sum_{z \in S } p_t(z, y) p_s(x, z).
\]</span>
To dowodzi a.
b. Użyjemy własności Markowa wielokrotnie, aby otrzymać
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = p_{t_1}(x, x_1) p_{t_2 - t_1}(x_1, x_2) \cdots p_{t_n - t_{n-1}}(x_{n-1}, x_n)
\]</span>
dla <span class="math inline">\(0 &lt; t_1 &lt; \ldots &lt; t_n\)</span> oraz <span class="math inline">\(x_1, \ldots, x_n \in S\)</span>.
Aby to zobaczyć oznaczmy
<span class="math display">\[
    \mathcal{H}_{n-1} = \{ X(t_1) = x_1, \ldots, X(t_{n-1}) = x_{n-1} \} \in \mathcal{F}_{t_{n-1}}.
\]</span>
Z własności Markowa
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{P}_x[\mathcal{H}_{n-1}, X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X(t_n) = x_n | \mathcal{F}_{t_{n-1}}]
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_x[X \circ \theta_{t_{n-1}} (t_n - t_{n-1}) = x_n | \mathcal{F}_{t_{n-1}}]
\]</span>
<span class="math display">\[
    = \mathbf{1}_{\mathcal{H}_{n-1}} \mathbf{P}_{X(t_{n-1})}[X (t_n - t_{n-1}) = x_n]
    = \mathbf{1}_{\mathcal{H}_{n-1}} p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Biorąc wartości oczekiwane,
<span class="math display">\[
    \mathbf{P}_x[X(t_1) = x_1, \ldots, X(t_n) = x_n]
    = \mathbf{P}_x[\mathcal{H}_{n-1}] p_{t_n - t_{n-1}}(x_{n-1}, x_n).
\]</span>
Postulowaną równość otrzymujemy przez iterację powyższej procedury.
Udowodniona właśnie równość uzasadnia,
że funkcja przejścia określa rozkłady skończenie wymiarowe <span class="math inline">\(\mathbf{P}_x\)</span>.
Określa również pełną miarę <span class="math inline">\(\mathbf{P}_x\)</span>,
ponieważ miary prawdopodobieństwa na <span class="math inline">\((\Omega, \mathcal{F})\)</span> są określane
przez ich skończenie wymiarowe rozkłady w świetle twierdzenia <span class="math inline">\(\pi - \lambda\)</span>.
Aby to zobaczyć, załóżmy, że <span class="math inline">\(\mu\)</span> oraz <span class="math inline">\(\nu\)</span> to dwie takie miary,
które mają te same skończenie wymiarowe rozkłady,
i niech <span class="math inline">\(\mathcal{P}\)</span> będą skończenie wymiarowymi zbiorami w <span class="math inline">\((\Omega, \mathcal{F})\)</span> oraz
<span class="math display">\[
    \mathcal{L} = \{ A \in \mathcal{F} : \mu(A) = \nu(A) \}.
\]</span>
Wówczas <span class="math inline">\(\mathcal{L}\)</span> jest <span class="math inline">\(\lambda\)</span>-układem zawierającym
<span class="math inline">\(\pi\)</span>-układ <span class="math inline">\(\mathcal{P}\)</span>.
Przez twierdzenie <span class="math inline">\(\pi - \lambda\)</span>,
<span class="math inline">\(\sigma(\mathcal{P}) \subseteq \mathcal{L}\)</span>.
Skoro <span class="math inline">\(\sigma(\mathcal{P}) = \mathcal{F}\)</span>,
to <span class="math inline">\(\mu(A) = \nu(A)\)</span> dla wszystkich <span class="math inline">\(A \in \mathcal{F}\)</span>.</p>
</div>
<p>Skoro <span class="math inline">\(X\)</span> jest elementem <span class="math inline">\(\Omega\)</span>,
zbioru funkcji prawostronnie ciągłych o wartościach w przeliczalnym <span class="math inline">\(S\)</span>,
to <span class="math inline">\(X\)</span> jest funkcją kawałkami stałą.
W rezultacie do opisu <span class="math inline">\(X\)</span> wystarczy sprecyzować,
w jaki sposób <span class="math inline">\(X\)</span> zmienia wartość.
Opis ten jest dokonywany w kategoriach <span class="math inline">\(Q\)</span>-macierzy.</p>
<div class="definition">
<p><span id="def:2-3" class="definition"><strong>Definicja 3  </strong></span><span class="math inline">\(Q\)</span>-macierzą nazywamy macierz <span class="math inline">\((q(x, y))_{x,y \in S}\)</span>
liczb rzeczywistych indeksowanych przez <span class="math inline">\(x, y \in S\)</span>,
które spełniają
<span class="math display">\[
q(x, y) \ge 0 \text{ dla } x \neq y \quad \text{oraz} \quad \sum_y q(x, y) = 0.
\]</span></p>
</div>
<p>Ponieważ wyrazy diagonalne są niedodatnie i
odgrywają specjalną rolę,
naturalne jest użycie specjalnego oznaczenia dla nich:
<span class="math display">\[
c(x) = -q(x, x).
\]</span>
Przejście od funkcji przejścia do <span class="math inline">\(Q\)</span>-macierzy
jest trudniejsze niż przejście od procesu do funkcji przejścia
i wymaga dokonania dodatkowych założeń.
Zaczynamy od kilku własności, które obowiązują dla wszystkich funkcji przejścia.</p>
<div class="theorem">
<p><span id="thm:2-13" class="theorem"><strong>Twierdzenie 2  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Wówczas <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla wszystkich <span class="math inline">\(t \ge 0\)</span> oraz <span class="math inline">\(x \in S\)</span>.</p></li>
<li><p>Jeśli <span class="math inline">\(p_t(x, x) = 1\)</span> dla pewnego <span class="math inline">\(t &gt; 0\)</span> oraz <span class="math inline">\(x \in S\)</span>, wtedy <span class="math inline">\(p_t(x, x) = 1\)</span> dla wszystkich <span class="math inline">\(t &gt; 0\)</span> oraz tego <span class="math inline">\(x\)</span>.</p></li>
<li><p>Dla każdego <span class="math inline">\(x, y \in S\)</span>, <span class="math inline">\(p_t(x, y)\)</span> jest jednostajnie ciągła w <span class="math inline">\(t\)</span>. Dokładniej,
<span class="math display">\[
   |p_t(x, y) - p_s(x, y)| \leq 1 - p_{|t-s|}(x, x).
\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Najpierw zauważmy, że <span class="math inline">\(p_t(x, x) &gt; 0\)</span> dla małych <span class="math inline">\(t\)</span> zgodnie z
przyjętą Definicją <a href="wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym.html#def:2-2">2</a>
Z równań Chapmana-Kołmogorowa,
<span class="math display">\[
p_{s+t}(x, x) \geq p_s(x, x)p_t(x, x),
\]</span>
więc ścisła dodatniość rozciąga się na wszystkie <span class="math inline">\(t\)</span>.</p></li>
<li><p>Użyjmy równania Chapmana-Kołmogorowa raz jeszcze, aby napisać
<span class="math display">\[
p_{s+t}(x, x) \leq p_s(x, x)p_t(x, x) + [1 - p_s(x, x)] = 1 - p_s(x, x)[1 - p_t(x, x)].
\]</span>
Zatem, jeśli <span class="math inline">\(p_{s+t}(x, x) = 1\)</span>, to <span class="math inline">\(p_t(x, x) = 1\)</span>,
ponieważ <span class="math inline">\(p_s(x, x) &gt; 0\)</span> z części a.
Stąd <span class="math inline">\(\{ t \ge 0 : p_t(x, x) = 1 \}\)</span> jest przedziałem zaczynającym się od 0.
Z dowodu części a. wynika, że musi to być cała dodatnia oś.</p></li>
<li><p>Ponownie użyjmy równania Chapmana-Kołmogorowa,
aby napisać
<span class="math display">\[
p_{t+s}(x, y) - p_t(x, y) = p_t(x, y)[p_s(x, x) - 1] + \sum_{z \neq x} p_s(x, z)p_t(z, y).
\]</span>
Pierwszy składnik po prawej stronie jest niedodatni,
a drugi jest nieujemny. Wartość bezwzględna każdego z nich nie jest większa niż <span class="math inline">\(1 - p_s(x, x)\)</span>.
To pociąga postulowaną nierówność, która z kolei pociąga jednostajną ciągłość.</p></li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:2-14" class="theorem"><strong>Twierdzenie 3  </strong></span>Załóżmy, że <span class="math inline">\(p\)</span> jest funkcją przejścia.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Dla każdego <span class="math inline">\(x\)</span>, prawostronna pochodna
<span class="math display">\[
     c(x) = -q(x, x) = - \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, x) \right|_{t=0} \in [0, \infty]
\]</span>
istnieje i spełnia
<span class="math display">\[
     p_t(x, x) \ge e^{-c(x)t}.
\]</span></p></li>
<li><p>Jeśli <span class="math inline">\(c(x) &lt; \infty\)</span>, wtedy dla tego <span class="math inline">\(x\)</span> i dla wszystkich <span class="math inline">\(y \neq x\)</span>, prawostronna pochodna
<span class="math display">\[
     q(x, y) = \left. \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) \right|_{t=0} \in [0, \infty)
\]</span>
istnieje oraz
<span class="math display">\[
     \sum_{y \in S} q(x, y) \leq 0.
\]</span></p></li>
<li><p>Jeśli dla pewnego <span class="math inline">\(x \in S\)</span>,
<span class="math inline">\(c(x) &lt; \infty\)</span> i <span class="math inline">\(\sum_y q(x, y) = 0\)</span>, to <span class="math inline">\(p_t(x, y)\)</span>
jest różniczkowalna w sposób ciągły względem <span class="math inline">\(t\)</span> dla tego <span class="math inline">\(x\)</span> i każdego <span class="math inline">\(y\)</span>,
oraz spełnia równania retrospektywne Kołmogorowa:
<span class="math display">\[
     \frac{\mathrm{d}}{\mathrm{d} t} p_t(x, y) = \sum_z q(x, z)p_t(z, y).
\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Niech <span class="math inline">\(f(t) = - \log p_t(x, x)\)</span>.
Wówczas <span class="math inline">\(f\)</span> jest dobrze określona i jednostajnie ciągła.
Jest ona też subaddytywna.
Zatem, zgodnie z Lematem Fekete,
<span class="math display">\[
c(x) = \lim_{t \to 0} \frac{f(t)}{t} \in [0, \infty]
\]</span>
i spełnia <span class="math inline">\(f(t) \leq c(x)t\)</span>.</p></li>
<li><p>Przypuśćmy, że <span class="math inline">\(c(x) &lt; \infty\)</span>. Z dowiedzionej właśnie nierówności,
<span class="math display">\[
1 - p_t(x, x) \leq 1 - e^{-c(x)t} \leq c(x)t,
\]</span>
i stąd
<span class="math display">\[
\sum_{y : y \neq x} \frac{p_t(x, y)}{t} \leq c(x).
\]</span>
Zatem,
<span class="math display" id="eq:2-1">\[
\limsup_{t \to 0} \frac{p_t(x, y)}{t} &lt; \infty
\tag{1}
\]</span>
dla <span class="math inline">\(y \neq x\)</span>.
Niech <span class="math inline">\(q(x, y)\)</span> będzie wartością powyższej granicy górnej.
Aby pokazać, że granica rzeczywiście istnieje,
weźmy <span class="math inline">\(\delta &gt; 0\)</span> i dodatnią liczbę całkowitą <span class="math inline">\(n\)</span>.
Macierz <span class="math inline">\(p_{\delta}(x, y)\)</span> można traktować jako prawdopodobieństwa
przejścia dla dyskretnego łańcucha Markowa na <span class="math inline">\(S\)</span>,
a wtedy zgodnie z równaniami Chapmana-Kołmogorowa,
odpowiadające <span class="math inline">\(n\)</span>-krokowe prawdopodobieństwa przejścia są dane przez <span class="math inline">\(p_{n\delta}(x, y)\)</span>.
Rozkładając zdarzenie,
że ten łańcuch znajduje się w <span class="math inline">\(y\)</span> w czasie <span class="math inline">\(n\)</span>
zgodnie z czasem pierwszej wizyty w <span class="math inline">\(y\)</span>, mamy dla <span class="math inline">\(y \neq x\)</span>,
<span class="math display">\[
p_{n\delta}(x, y) \geq \sum_{k=0}^{n-1} p_{k\delta}^k(x, x) p_{\delta}(x, y)p_{(n-k-1)\delta}(y, y).
\]</span>
Stąd
<span class="math display">\[
\frac{p_{n\delta}(x, y)}{n\delta}
\geq \frac{p_{\delta}(x, y)}{\delta} e^{-c(x)n\delta} \inf_{0 \leq s \leq n\delta} p_s(y, y).
\]</span>
Teraz niech <span class="math inline">\(\delta \downarrow 0\)</span> wzdłuż
ciągu realizującego granicę górną w <a href="wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym.html#eq:2-1">(1)</a>, tak że
<span class="math display">\[
\frac{p_{\delta}(x, y)}{\delta} \to q(x, y).
\]</span>
Wybierzmy teraz <span class="math inline">\(n \to \infty\)</span> tak, że <span class="math inline">\(n\delta \to t\)</span>. Wówczas
<span class="math display">\[
\frac{p_t(x, y)}{t} \geq q(x, y)e^{-c(x)t} \inf_{0 \leq s \leq t} p_s(y, y)
\]</span>
dla <span class="math inline">\(t &gt; 0\)</span>. Zatem,
<span class="math display">\[
\liminf_{t \to 0} \frac{p_t(x, y)}{t} \geq q(x, y).
\]</span>
Postulowana nierówność wynika teraz z lematu Fatou.</p></li>
<li><p>Napiszmy
<span class="math display">\[
\frac{p_{t+s}(x, y) - p_t(x, y)}{s} = \sum_z \left[ \frac{p_s(x, z) - p_0(x, z)}{s} - q(x, z) \right] p_t(z, y).
\]</span>
Każdy wyraz w sumie dąży do <span class="math inline">\(0\)</span>, gdy <span class="math inline">\(s \downarrow 0\)</span>,
zgodnie z pierwszymi dwoma częściami twierdzenia.
Zatem musimy kontrolować ogony sumy.
Weźmy skończony zbiór <span class="math inline">\(T \subset S\)</span> zawierający <span class="math inline">\(x\)</span> i zauważmy, że
<span class="math display">\[
\sum_{z \notin T} \left| \frac{p_s(x, z)}{s} - q(x, z) \right| p_t(z, y) \leq \sum_{z \notin T} \frac{p_s(x, z)}{s} + \sum_{z \notin T} q(x, z)
\]</span>
<span class="math display">\[
= s^{-1} \left[ 1 - \sum_{z \in T} p_s(x, z) \right] - \sum_{z \in T} q(x, z) \to -2 \sum_{z \in T} q(x, z)
\]</span>
gdy <span class="math inline">\(s \downarrow 0\)</span>.
Granicę po prawej stronie można uczynić dowolnie małą,
wybierając <span class="math inline">\(T\)</span> duże, ponieważ <span class="math inline">\(\sum_z q(x, z) = 0\)</span>.
Zatem prawa strona dąży do zera,
gdy <span class="math inline">\(s \downarrow 0\)</span>. To dowodzi, że prawostronne pochodne <span class="math inline">\(p_t(x, y)\)</span>
istnieją i spełniają zadaną równość.
Aby zobaczyć, że obustronne pochodne rzeczywiście istnieją,
wystarczy zauważyć, że prawa strona jest ciągła w <span class="math inline">\(t\)</span> i użyć faktu,
że funkcja ciągła z ciągłą prawostronną pochodną jest różniczkowalna.</p></li>
</ol>
</div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sylabus.html">Sylabus</a></div>
<div class="next"><a href="wyk%C5%82ad-2-mocna-w%C5%82asno%C5%9B%C4%87-markowa.html">Wykład 2: Mocna własność Markowa</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#wyk%C5%82ad-1-%C5%82a%C5%84cuchy-markowa-w-czasie-ci%C4%85g%C5%82ym">Wykład 1: Łańcuchy Markowa w czasie ciągłym</a></li>
<li><a class="nav-link" href="#podstawowe-definicje">Podstawowe definicje</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Stochastyczne modele układów oddziałujących 2024</strong>: Notatni do wykładu" was written by Piotr Dyszewski. It was last built on 2025-01-17.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
